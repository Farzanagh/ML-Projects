{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Farzanagh/ML-Projects/blob/main/Anti_Diabetic_Peptide_identification_using_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mB1UiPOdHSF"
      },
      "source": [
        "#**TPC**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_19ZEss0U3-K",
        "outputId": "445d9d35-7d25-4749-8fef-7f1fe58641c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lin_score=  0.3331134861263254\n",
            "r2_score=  0.3331134861263254\n",
            "Acaccury_score=  0.795774647887324\n",
            "Sensitivity= 0.75\n",
            "Specificity= 0.8428571428571429\n",
            "MCC: 0.5949264585479017\n",
            "Kappa Value: 0.5920348722013077\n",
            "\n",
            "\n",
            "\n",
            "LR_score=  0.647887323943662\n",
            "r2_score=  -0.4087301587301584\n",
            "Acaccury_score=  0.647887323943662\n",
            "Sensitivity= 0.3611111111111111\n",
            "Specificity= 0.9428571428571428\n",
            "MCC: 0.3722835601134751\n",
            "Kappa Value: 0.30145611963793784\n",
            "\n",
            "\n",
            "\n",
            "DT_score=  0.6126760563380281\n",
            "r2_score=  -0.5496031746031744\n",
            "Acaccury_score=  0.6126760563380281\n",
            "Sensitivity= 0.3333333333333333\n",
            "Specificity= 0.9\n",
            "MCC: 0.28239026256126765\n",
            "Kappa Value: 0.23145050186971072\n",
            "\n",
            "\n",
            "\n",
            "RF_score=  0.6197183098591549\n",
            "r2_score=  -0.5214285714285711\n",
            "Acaccury_score=  0.6197183098591549\n",
            "Sensitivity= 0.3055555555555556\n",
            "Specificity= 0.9428571428571428\n",
            "MCC: 0.3211244637587885\n",
            "Kappa Value: 0.2461659457333858\n",
            "\n",
            "\n",
            "\n",
            "ETC_score=  0.6619718309859155\n",
            "r2_score=  -0.35238095238095224\n",
            "Acaccury_score=  0.6619718309859155\n",
            "Sensitivity= 0.3611111111111111\n",
            "Specificity= 0.9714285714285714\n",
            "MCC: 0.4178566370814772\n",
            "Kappa Value: 0.32966168371361126\n",
            "\n",
            "\n",
            "\n",
            "GBC_score=  0.5774647887323944\n",
            "r2_score=  -0.6904761904761902\n",
            "Acaccury_score=  0.5774647887323944\n",
            "Sensitivity= 0.2916666666666667\n",
            "Specificity= 0.8714285714285714\n",
            "MCC: 0.19975005640553298\n",
            "Kappa Value: 0.16174734356552545\n",
            "\n",
            "\n",
            "\n",
            "5/5 [==============================] - 0s 5ms/step\n",
            "r2_score=  0.07023809523809543\n",
            "Accuracy= 0.7676056338028169\n",
            "Sensitivity= 0.7361111111111112\n",
            "Specificity= 0.8\n",
            "MCC: 0.5369106806994982\n",
            "Kappa Value: 0.5355797819623389\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "df=pd.read_csv('/content/TPC data.csv')\n",
        "# print(df.head(10))\n",
        "# print (df.isnull().any())\n",
        "x=df.drop('Target', axis=1)\n",
        "y=df['Target']\n",
        "x_train,x_test,y_train,y_test= train_test_split(x,y,test_size=0.30, random_state=8)\n",
        "\n",
        "#Linear Regression\n",
        "clf= LinearRegression()\n",
        "clf.fit(x_train,y_train)\n",
        "LinearRegression()\n",
        "pred=clf.predict(x_test)\n",
        "pred_labels = [round(value) for value in pred]\n",
        "\n",
        "lin_score= clf.score(x_test,y_test)\n",
        "print(\"Lin_score= \",lin_score)\n",
        "from sklearn.metrics import r2_score\n",
        "r2_score=r2_score(y_test,pred)\n",
        "print(\"r2_score= \",r2_score)\n",
        "from sklearn.metrics import accuracy_score #accuracy check\n",
        "acaccury_score= accuracy_score(y_test,pred_labels)\n",
        "print(\"Acaccury_score= \",acaccury_score)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn,fp,fn,tp= confusion_matrix(y_test,pred_labels).ravel()\n",
        "sensitivity= tp/(tp+fn)\n",
        "specificity= tn/(tn+fp)\n",
        "print(f\"Sensitivity= {sensitivity}\")\n",
        "print(f\"Specificity= {specificity}\")\n",
        "from sklearn.metrics import matthews_corrcoef # Calculate Matthews Correlation Coefficient (MCC)\n",
        "mcc = matthews_corrcoef(y_test, pred_labels)\n",
        "print(f\"MCC: {mcc}\")\n",
        "\n",
        "from sklearn.metrics import cohen_kappa_score # Calculate Kappa Value\n",
        "kappa = cohen_kappa_score(y_test, pred_labels)\n",
        "print(f\"Kappa Value: {kappa}\")\n",
        "\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "\n",
        "#Logistic Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "clf=LogisticRegression()\n",
        "clf.fit(x_train,y_train)\n",
        "LogisticRegression()\n",
        "pred=clf.predict(x_test)\n",
        "log_score=clf.score(x_test,y_test)\n",
        "print(\"LR_score= \",log_score)\n",
        "from sklearn.metrics import r2_score\n",
        "r2_score= r2_score(y_test,pred)\n",
        "print(\"r2_score= \",r2_score)\n",
        "from sklearn.metrics import accuracy_score #accuracy check\n",
        "acaccury_score= accuracy_score(y_test,pred)\n",
        "print(\"Acaccury_score= \",acaccury_score)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn,fp,fn,tp= confusion_matrix(y_test,pred).ravel()\n",
        "sensitivity= tp/(tp+fn)\n",
        "specificity= tn/(tn+fp)\n",
        "print(f\"Sensitivity= {sensitivity}\")\n",
        "print(f\"Specificity= {specificity}\")\n",
        "from sklearn.metrics import matthews_corrcoef # Calculate Matthews Correlation Coefficient (MCC)\n",
        "mcc = matthews_corrcoef(y_test, pred)\n",
        "print(f\"MCC: {mcc}\")\n",
        "\n",
        "from sklearn.metrics import cohen_kappa_score # Calculate Kappa Value\n",
        "kappa = cohen_kappa_score(y_test, pred)\n",
        "print(f\"Kappa Value: {kappa}\")\n",
        "\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "\n",
        "#Decision Tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "clf=DecisionTreeClassifier()\n",
        "clf.fit(x_train,y_train)\n",
        "DecisionTreeClassifier()\n",
        "pred=clf.predict(x_test)\n",
        "dt_score=clf.score(x_test,y_test)\n",
        "print(\"DT_score= \",dt_score)\n",
        "from sklearn.metrics import r2_score\n",
        "r2_score= r2_score(y_test,pred)\n",
        "print(\"r2_score= \",r2_score)\n",
        "from sklearn.metrics import accuracy_score #accuracy check\n",
        "acaccury_score= accuracy_score(y_test,pred)\n",
        "print(\"Acaccury_score= \",acaccury_score)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn,fp,fn,tp= confusion_matrix(y_test,pred).ravel()\n",
        "sensitivity= tp/(tp+fn)\n",
        "specificity= tn/(tn+fp)\n",
        "print(f\"Sensitivity= {sensitivity}\")\n",
        "print(f\"Specificity= {specificity}\")\n",
        "from sklearn.metrics import matthews_corrcoef # Calculate Matthews Correlation Coefficient (MCC)\n",
        "mcc = matthews_corrcoef(y_test, pred)\n",
        "print(f\"MCC: {mcc}\")\n",
        "\n",
        "from sklearn.metrics import cohen_kappa_score # Calculate Kappa Value\n",
        "kappa = cohen_kappa_score(y_test, pred)\n",
        "print(f\"Kappa Value: {kappa}\")\n",
        "print(\"\\n\\n\")\n",
        "# from sklearn import tree\n",
        "# tree.plot_tree(clf, filled=True, rounded=True, feature_names=x.columns)\n",
        "# plt.figure(figsize=(10,50))\n",
        "\n",
        "\n",
        "#Random Forest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "clf=RandomForestClassifier()\n",
        "clf.fit(x_train,y_train)\n",
        "RandomForestClassifier()\n",
        "pred=clf.predict(x_test)\n",
        "rf_score=clf.score(x_test,y_test)\n",
        "print(\"RF_score= \",rf_score)\n",
        "from sklearn.metrics import r2_score\n",
        "r2_score= r2_score(y_test,pred)\n",
        "print(\"r2_score= \",r2_score)\n",
        "from sklearn.metrics import accuracy_score #accuracy check\n",
        "acaccury_score= accuracy_score(y_test,pred)\n",
        "print(\"Acaccury_score= \",acaccury_score)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn,fp,fn,tp= confusion_matrix(y_test,pred).ravel()\n",
        "sensitivity= tp/(tp+fn)\n",
        "specificity= tn/(tn+fp)\n",
        "print(f\"Sensitivity= {sensitivity}\")\n",
        "print(f\"Specificity= {specificity}\")\n",
        "from sklearn.metrics import matthews_corrcoef # Calculate Matthews Correlation Coefficient (MCC)\n",
        "mcc = matthews_corrcoef(y_test, pred)\n",
        "print(f\"MCC: {mcc}\")\n",
        "\n",
        "from sklearn.metrics import cohen_kappa_score # Calculate Kappa Value\n",
        "kappa = cohen_kappa_score(y_test, pred)\n",
        "print(f\"Kappa Value: {kappa}\")\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "#Extra Tree Classifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "clf=ExtraTreesClassifier()\n",
        "clf.fit(x_train,y_train)\n",
        "ExtraTreesClassifier()\n",
        "pred=clf.predict(x_test)\n",
        "etc_score=clf.score(x_test,y_test)\n",
        "print(\"ETC_score= \",etc_score)\n",
        "from sklearn.metrics import r2_score\n",
        "r2_score= r2_score(y_test,pred)\n",
        "print(\"r2_score= \",r2_score)\n",
        "from sklearn.metrics import accuracy_score #accuracy check\n",
        "acaccury_score= accuracy_score(y_test,pred)\n",
        "print(\"Acaccury_score= \",acaccury_score)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn,fp,fn,tp= confusion_matrix(y_test,pred).ravel()\n",
        "sensitivity= tp/(tp+fn)\n",
        "specificity= tn/(tn+fp)\n",
        "print(f\"Sensitivity= {sensitivity}\")\n",
        "print(f\"Specificity= {specificity}\")\n",
        "from sklearn.metrics import matthews_corrcoef # Calculate Matthews Correlation Coefficient (MCC)\n",
        "mcc = matthews_corrcoef(y_test, pred)\n",
        "print(f\"MCC: {mcc}\")\n",
        "\n",
        "from sklearn.metrics import cohen_kappa_score # Calculate Kappa Value\n",
        "kappa = cohen_kappa_score(y_test, pred)\n",
        "print(f\"Kappa Value: {kappa}\")\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "#Gradient Boosting Classifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "clf=GradientBoostingClassifier()\n",
        "clf.fit(x_train,y_train)\n",
        "GradientBoostingClassifier()\n",
        "pred=clf.predict(x_test)\n",
        "gbc_score=clf.score(x_test,y_test)\n",
        "print(\"GBC_score= \",gbc_score)\n",
        "from sklearn.metrics import r2_score\n",
        "r2_score= r2_score(y_test,pred)\n",
        "print(\"r2_score= \",r2_score)\n",
        "from sklearn.metrics import accuracy_score #accuracy check\n",
        "acaccury_score= accuracy_score(y_test,pred)\n",
        "print(\"Acaccury_score= \",acaccury_score)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn,fp,fn,tp= confusion_matrix(y_test,pred).ravel()\n",
        "sensitivity= tp/(tp+fn)\n",
        "specificity= tn/(tn+fp)\n",
        "print(f\"Sensitivity= {sensitivity}\")\n",
        "print(f\"Specificity= {specificity}\")\n",
        "from sklearn.metrics import matthews_corrcoef # Calculate Matthews Correlation Coefficient (MCC)\n",
        "mcc = matthews_corrcoef(y_test, pred)\n",
        "print(f\"MCC: {mcc}\")\n",
        "\n",
        "from sklearn.metrics import cohen_kappa_score # Calculate Kappa Value\n",
        "kappa = cohen_kappa_score(y_test, pred)\n",
        "print(f\"Kappa Value: {kappa}\")\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "\n",
        "#neural\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, matthews_corrcoef, cohen_kappa_score\n",
        "from sklearn.svm import SVC\n",
        "df=pd.read_csv('/content/TPC data.csv')\n",
        "# print(df.head(10))\n",
        "# print (df.isnull().any())\n",
        "x=df.drop('Target', axis=1)\n",
        "y=df['Target']\n",
        "x_train,x_test,y_train,y_test= train_test_split(x,y,test_size=0.30, random_state=8)\n",
        "\n",
        "#Neural Networks\n",
        "clf = keras.Sequential([\n",
        "    keras.layers.Dense(32, activation='relu', input_shape=(x_train.shape[1],)),\n",
        "    keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "clf.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "clf.fit(x_train, y_train, epochs=100, batch_size=32, verbose=0)\n",
        "pred = (model.predict(x_test) > 0.5).astype(int).flatten()# Make predictions on the testing data\n",
        "####nn_score=clf.score(x_test,y_test)\n",
        "###print(f'NN_score= {nn_score}')\n",
        "from sklearn.metrics import r2_score\n",
        "r2_score= r2_score(y_test,pred)\n",
        "print(\"r2_score= \",r2_score)\n",
        "accuracy = accuracy_score(y_test, pred)# Calculate Accuracy\n",
        "print(f\"Accuracy= {accuracy}\")\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, predictions).ravel()# Calculate Sensitivity and Specificity\n",
        "sensitivity = tp / (tp + fn)\n",
        "specificity = tn / (tn + fp)\n",
        "print(f\"Sensitivity= {sensitivity}\")\n",
        "print(f\"Specificity= {specificity}\")\n",
        "\n",
        "# Calculate Matthews Correlation Coefficient (MCC)\n",
        "mcc = matthews_corrcoef(y_test, pred)\n",
        "print(f\"MCC: {mcc}\")\n",
        "\n",
        "# Calculate Kappa Value\n",
        "kappa = cohen_kappa_score(y_test, pred)\n",
        "print(f\"Kappa Value: {kappa}\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**AAC**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "Oie-rSGltIwi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "_ptAqlhahOU1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14ea3161-d13f-4174-9a51-084f7d9a9650"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lin_score=  0.06529137345831726\n",
            "r2_score=  0.06529137345831726\n",
            "Acaccury_score=  0.6267605633802817\n",
            "Sensitivity= 0.6285714285714286\n",
            "Specificity= 0.625\n",
            "MCC: 0.253546276418555\n",
            "Kappa Value: 0.2535211267605634\n",
            "\n",
            "\n",
            "\n",
            "LR_score=  0.6338028169014085\n",
            "r2_score=  -0.46507936507936476\n",
            "Acaccury_score=  0.6338028169014085\n",
            "Sensitivity= 0.6714285714285714\n",
            "Specificity= 0.5972222222222222\n",
            "MCC: 0.26929273194630005\n",
            "Kappa Value: 0.2683313515655965\n",
            "\n",
            "\n",
            "\n",
            "DT_score=  0.6267605633802817\n",
            "r2_score=  -0.49325396825396806\n",
            "Acaccury_score=  0.6267605633802817\n",
            "Sensitivity= 0.5142857142857142\n",
            "Specificity= 0.7361111111111112\n",
            "MCC: 0.2569822431244085\n",
            "Kappa Value: 0.2511442786069651\n",
            "\n",
            "\n",
            "\n",
            "RF_score=  0.6126760563380281\n",
            "r2_score=  -0.5496031746031744\n",
            "Acaccury_score=  0.6126760563380281\n",
            "Sensitivity= 0.5428571428571428\n",
            "Specificity= 0.6805555555555556\n",
            "MCC: 0.2256397944092039\n",
            "Kappa Value: 0.2238123633472472\n",
            "\n",
            "\n",
            "\n",
            "ETC_score=  0.6830985915492958\n",
            "r2_score=  -0.26785714285714257\n",
            "Acaccury_score=  0.6830985915492958\n",
            "Sensitivity= 0.6714285714285714\n",
            "Specificity= 0.6944444444444444\n",
            "MCC: 0.36598195528762983\n",
            "Kappa Value: 0.3659456241317721\n",
            "\n",
            "\n",
            "\n",
            "GBC_score=  0.6338028169014085\n",
            "r2_score=  -0.46507936507936476\n",
            "Acaccury_score=  0.6338028169014085\n",
            "Sensitivity= 0.6571428571428571\n",
            "Specificity= 0.6111111111111112\n",
            "MCC: 0.2684671220168447\n",
            "Kappa Value: 0.2680412371134021\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "df=pd.read_csv('/content/AAC data.csv')\n",
        "# print(df.head(10))\n",
        "# print (df.isnull().any())\n",
        "x=df.drop('Target', axis=1)\n",
        "y=df['Target']\n",
        "x_train,x_test,y_train,y_test= train_test_split(x,y,test_size=0.30, random_state=8)\n",
        "\n",
        "#Linear Regression\n",
        "clf= LinearRegression()\n",
        "clf.fit(x_train,y_train)\n",
        "LinearRegression()\n",
        "pred=clf.predict(x_test)\n",
        "pred_labels = [round(value) for value in pred]\n",
        "\n",
        "lin_score= clf.score(x_test,y_test)\n",
        "print(\"Lin_score= \",lin_score)\n",
        "from sklearn.metrics import r2_score\n",
        "r2_score=r2_score(y_test,pred)\n",
        "print(\"r2_score= \",r2_score)\n",
        "from sklearn.metrics import accuracy_score #accuracy check\n",
        "acaccury_score= accuracy_score(y_test,pred_labels)\n",
        "print(\"Acaccury_score= \",acaccury_score)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn,fp,fn,tp= confusion_matrix(y_test,pred_labels).ravel()\n",
        "sensitivity= tp/(tp+fn)\n",
        "specificity= tn/(tn+fp)\n",
        "print(f\"Sensitivity= {sensitivity}\")\n",
        "print(f\"Specificity= {specificity}\")\n",
        "from sklearn.metrics import matthews_corrcoef # Calculate Matthews Correlation Coefficient (MCC)\n",
        "mcc = matthews_corrcoef(y_test, pred_labels)\n",
        "print(f\"MCC: {mcc}\")\n",
        "\n",
        "from sklearn.metrics import cohen_kappa_score # Calculate Kappa Value\n",
        "kappa = cohen_kappa_score(y_test, pred_labels)\n",
        "print(f\"Kappa Value: {kappa}\")\n",
        "\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "\n",
        "#Logistic Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "clf=LogisticRegression()\n",
        "clf.fit(x_train,y_train)\n",
        "LogisticRegression()\n",
        "pred=clf.predict(x_test)\n",
        "log_score=clf.score(x_test,y_test)\n",
        "print(\"LR_score= \",log_score)\n",
        "from sklearn.metrics import r2_score\n",
        "r2_score= r2_score(y_test,pred)\n",
        "print(\"r2_score= \",r2_score)\n",
        "from sklearn.metrics import accuracy_score #accuracy check\n",
        "acaccury_score= accuracy_score(y_test,pred)\n",
        "print(\"Acaccury_score= \",acaccury_score)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn,fp,fn,tp= confusion_matrix(y_test,pred).ravel()\n",
        "sensitivity= tp/(tp+fn)\n",
        "specificity= tn/(tn+fp)\n",
        "print(f\"Sensitivity= {sensitivity}\")\n",
        "print(f\"Specificity= {specificity}\")\n",
        "from sklearn.metrics import matthews_corrcoef # Calculate Matthews Correlation Coefficient (MCC)\n",
        "mcc = matthews_corrcoef(y_test, pred)\n",
        "print(f\"MCC: {mcc}\")\n",
        "\n",
        "from sklearn.metrics import cohen_kappa_score # Calculate Kappa Value\n",
        "kappa = cohen_kappa_score(y_test, pred)\n",
        "print(f\"Kappa Value: {kappa}\")\n",
        "\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "\n",
        "#Decision Tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "clf=DecisionTreeClassifier()\n",
        "clf.fit(x_train,y_train)\n",
        "DecisionTreeClassifier()\n",
        "pred=clf.predict(x_test)\n",
        "dt_score=clf.score(x_test,y_test)\n",
        "print(\"DT_score= \",dt_score)\n",
        "from sklearn.metrics import r2_score\n",
        "r2_score= r2_score(y_test,pred)\n",
        "print(\"r2_score= \",r2_score)\n",
        "from sklearn.metrics import accuracy_score #accuracy check\n",
        "acaccury_score= accuracy_score(y_test,pred)\n",
        "print(\"Acaccury_score= \",acaccury_score)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn,fp,fn,tp= confusion_matrix(y_test,pred).ravel()\n",
        "sensitivity= tp/(tp+fn)\n",
        "specificity= tn/(tn+fp)\n",
        "print(f\"Sensitivity= {sensitivity}\")\n",
        "print(f\"Specificity= {specificity}\")\n",
        "from sklearn.metrics import matthews_corrcoef # Calculate Matthews Correlation Coefficient (MCC)\n",
        "mcc = matthews_corrcoef(y_test, pred)\n",
        "print(f\"MCC: {mcc}\")\n",
        "\n",
        "from sklearn.metrics import cohen_kappa_score # Calculate Kappa Value\n",
        "kappa = cohen_kappa_score(y_test, pred)\n",
        "print(f\"Kappa Value: {kappa}\")\n",
        "print(\"\\n\\n\")\n",
        "# from sklearn import tree\n",
        "# tree.plot_tree(clf, filled=True, rounded=True, feature_names=x.columns)\n",
        "# plt.figure(figsize=(10,50))\n",
        "\n",
        "\n",
        "#Random Forest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "clf=RandomForestClassifier()\n",
        "clf.fit(x_train,y_train)\n",
        "RandomForestClassifier()\n",
        "pred=clf.predict(x_test)\n",
        "rf_score=clf.score(x_test,y_test)\n",
        "print(\"RF_score= \",rf_score)\n",
        "from sklearn.metrics import r2_score\n",
        "r2_score= r2_score(y_test,pred)\n",
        "print(\"r2_score= \",r2_score)\n",
        "from sklearn.metrics import accuracy_score #accuracy check\n",
        "acaccury_score= accuracy_score(y_test,pred)\n",
        "print(\"Acaccury_score= \",acaccury_score)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn,fp,fn,tp= confusion_matrix(y_test,pred).ravel()\n",
        "sensitivity= tp/(tp+fn)\n",
        "specificity= tn/(tn+fp)\n",
        "print(f\"Sensitivity= {sensitivity}\")\n",
        "print(f\"Specificity= {specificity}\")\n",
        "from sklearn.metrics import matthews_corrcoef # Calculate Matthews Correlation Coefficient (MCC)\n",
        "mcc = matthews_corrcoef(y_test, pred)\n",
        "print(f\"MCC: {mcc}\")\n",
        "\n",
        "from sklearn.metrics import cohen_kappa_score # Calculate Kappa Value\n",
        "kappa = cohen_kappa_score(y_test, pred)\n",
        "print(f\"Kappa Value: {kappa}\")\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "#Extra Tree Classifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "clf=ExtraTreesClassifier()\n",
        "clf.fit(x_train,y_train)\n",
        "ExtraTreesClassifier()\n",
        "pred=clf.predict(x_test)\n",
        "etc_score=clf.score(x_test,y_test)\n",
        "print(\"ETC_score= \",etc_score)\n",
        "from sklearn.metrics import r2_score\n",
        "r2_score= r2_score(y_test,pred)\n",
        "print(\"r2_score= \",r2_score)\n",
        "from sklearn.metrics import accuracy_score #accuracy check\n",
        "acaccury_score= accuracy_score(y_test,pred)\n",
        "print(\"Acaccury_score= \",acaccury_score)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn,fp,fn,tp= confusion_matrix(y_test,pred).ravel()\n",
        "sensitivity= tp/(tp+fn)\n",
        "specificity= tn/(tn+fp)\n",
        "print(f\"Sensitivity= {sensitivity}\")\n",
        "print(f\"Specificity= {specificity}\")\n",
        "from sklearn.metrics import matthews_corrcoef # Calculate Matthews Correlation Coefficient (MCC)\n",
        "mcc = matthews_corrcoef(y_test, pred)\n",
        "print(f\"MCC: {mcc}\")\n",
        "\n",
        "from sklearn.metrics import cohen_kappa_score # Calculate Kappa Value\n",
        "kappa = cohen_kappa_score(y_test, pred)\n",
        "print(f\"Kappa Value: {kappa}\")\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "#Gradient Boosting Classifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "clf=GradientBoostingClassifier()\n",
        "clf.fit(x_train,y_train)\n",
        "GradientBoostingClassifier()\n",
        "pred=clf.predict(x_test)\n",
        "gbc_score=clf.score(x_test,y_test)\n",
        "print(\"GBC_score= \",gbc_score)\n",
        "from sklearn.metrics import r2_score\n",
        "r2_score= r2_score(y_test,pred)\n",
        "print(\"r2_score= \",r2_score)\n",
        "from sklearn.metrics import accuracy_score #accuracy check\n",
        "acaccury_score= accuracy_score(y_test,pred)\n",
        "print(\"Acaccury_score= \",acaccury_score)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn,fp,fn,tp= confusion_matrix(y_test,pred).ravel()\n",
        "sensitivity= tp/(tp+fn)\n",
        "specificity= tn/(tn+fp)\n",
        "print(f\"Sensitivity= {sensitivity}\")\n",
        "print(f\"Specificity= {specificity}\")\n",
        "from sklearn.metrics import matthews_corrcoef # Calculate Matthews Correlation Coefficient (MCC)\n",
        "mcc = matthews_corrcoef(y_test, pred)\n",
        "print(f\"MCC: {mcc}\")\n",
        "\n",
        "from sklearn.metrics import cohen_kappa_score # Calculate Kappa Value\n",
        "kappa = cohen_kappa_score(y_test, pred)\n",
        "print(f\"Kappa Value: {kappa}\")\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**CKSAAP**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "pN0mfiINtr5G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "df=pd.read_csv('/content/CKSAAP data.csv')\n",
        "# print(df.head(10))\n",
        "# print (df.isnull().any())\n",
        "x=df.drop('Target', axis=1)\n",
        "y=df['Target']\n",
        "x_train,x_test,y_train,y_test= train_test_split(x,y,test_size=0.30, random_state=4)\n",
        "\n",
        "#Linear Regression\n",
        "clf= LinearRegression()\n",
        "clf.fit(x_train,y_train)\n",
        "LinearRegression()\n",
        "pred=clf.predict(x_test)\n",
        "pred_labels = [round(value) for value in pred]\n",
        "\n",
        "lin_score= clf.score(x_test,y_test)\n",
        "print(\"Lin_score= \",lin_score)\n",
        "from sklearn.metrics import r2_score\n",
        "r2_score=r2_score(y_test,pred)\n",
        "print(\"r2_score= \",r2_score)\n",
        "from sklearn.metrics import accuracy_score #accuracy check\n",
        "acaccury_score= accuracy_score(y_test,pred_labels)\n",
        "print(\"Acaccury_score= \",acaccury_score)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn,fp,fn,tp= confusion_matrix(y_test,pred_labels).ravel()\n",
        "sensitivity= tp/(tp+fn)\n",
        "specificity= tn/(tn+fp)\n",
        "print(f\"Sensitivity= {sensitivity}\")\n",
        "print(f\"Specificity= {specificity}\")\n",
        "from sklearn.metrics import matthews_corrcoef # Calculate Matthews Correlation Coefficient (MCC)\n",
        "mcc = matthews_corrcoef(y_test, pred_labels)\n",
        "print(f\"MCC: {mcc}\")\n",
        "\n",
        "from sklearn.metrics import cohen_kappa_score # Calculate Kappa Value\n",
        "kappa = cohen_kappa_score(y_test, pred_labels)\n",
        "print(f\"Kappa Value: {kappa}\")\n",
        "\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "\n",
        "#Logistic Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "clf=LogisticRegression()\n",
        "clf.fit(x_train,y_train)\n",
        "LogisticRegression()\n",
        "pred=clf.predict(x_test)\n",
        "log_score=clf.score(x_test,y_test)\n",
        "print(\"LR_score= \",log_score)\n",
        "from sklearn.metrics import r2_score\n",
        "r2_score= r2_score(y_test,pred)\n",
        "print(\"r2_score= \",r2_score)\n",
        "from sklearn.metrics import accuracy_score #accuracy check\n",
        "acaccury_score= accuracy_score(y_test,pred)\n",
        "print(\"Acaccury_score= \",acaccury_score)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn,fp,fn,tp= confusion_matrix(y_test,pred).ravel()\n",
        "sensitivity= tp/(tp+fn)\n",
        "specificity= tn/(tn+fp)\n",
        "print(f\"Sensitivity= {sensitivity}\")\n",
        "print(f\"Specificity= {specificity}\")\n",
        "from sklearn.metrics import matthews_corrcoef # Calculate Matthews Correlation Coefficient (MCC)\n",
        "mcc = matthews_corrcoef(y_test, pred)\n",
        "print(f\"MCC: {mcc}\")\n",
        "\n",
        "from sklearn.metrics import cohen_kappa_score # Calculate Kappa Value\n",
        "kappa = cohen_kappa_score(y_test, pred)\n",
        "print(f\"Kappa Value: {kappa}\")\n",
        "\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "\n",
        "#Decision Tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "clf=DecisionTreeClassifier()\n",
        "clf.fit(x_train,y_train)\n",
        "DecisionTreeClassifier()\n",
        "pred=clf.predict(x_test)\n",
        "dt_score=clf.score(x_test,y_test)\n",
        "print(\"DT_score= \",dt_score)\n",
        "from sklearn.metrics import r2_score\n",
        "r2_score= r2_score(y_test,pred)\n",
        "print(\"r2_score= \",r2_score)\n",
        "from sklearn.metrics import accuracy_score #accuracy check\n",
        "acaccury_score= accuracy_score(y_test,pred)\n",
        "print(\"Acaccury_score= \",acaccury_score)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn,fp,fn,tp= confusion_matrix(y_test,pred).ravel()\n",
        "sensitivity= tp/(tp+fn)\n",
        "specificity= tn/(tn+fp)\n",
        "print(f\"Sensitivity= {sensitivity}\")\n",
        "print(f\"Specificity= {specificity}\")\n",
        "from sklearn.metrics import matthews_corrcoef # Calculate Matthews Correlation Coefficient (MCC)\n",
        "mcc = matthews_corrcoef(y_test, pred)\n",
        "print(f\"MCC: {mcc}\")\n",
        "\n",
        "from sklearn.metrics import cohen_kappa_score # Calculate Kappa Value\n",
        "kappa = cohen_kappa_score(y_test, pred)\n",
        "print(f\"Kappa Value: {kappa}\")\n",
        "print(\"\\n\\n\")\n",
        "# from sklearn import tree\n",
        "# tree.plot_tree(clf, filled=True, rounded=True, feature_names=x.columns)\n",
        "# plt.figure(figsize=(10,50))\n",
        "\n",
        "\n",
        "#Random Forest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "clf=RandomForestClassifier()\n",
        "clf.fit(x_train,y_train)\n",
        "RandomForestClassifier()\n",
        "pred=clf.predict(x_test)\n",
        "rf_score=clf.score(x_test,y_test)\n",
        "print(\"RF_score= \",rf_score)\n",
        "from sklearn.metrics import r2_score\n",
        "r2_score= r2_score(y_test,pred)\n",
        "print(\"r2_score= \",r2_score)\n",
        "from sklearn.metrics import accuracy_score #accuracy check\n",
        "acaccury_score= accuracy_score(y_test,pred)\n",
        "print(\"Acaccury_score= \",acaccury_score)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn,fp,fn,tp= confusion_matrix(y_test,pred).ravel()\n",
        "sensitivity= tp/(tp+fn)\n",
        "specificity= tn/(tn+fp)\n",
        "print(f\"Sensitivity= {sensitivity}\")\n",
        "print(f\"Specificity= {specificity}\")\n",
        "from sklearn.metrics import matthews_corrcoef # Calculate Matthews Correlation Coefficient (MCC)\n",
        "mcc = matthews_corrcoef(y_test, pred)\n",
        "print(f\"MCC: {mcc}\")\n",
        "\n",
        "from sklearn.metrics import cohen_kappa_score # Calculate Kappa Value\n",
        "kappa = cohen_kappa_score(y_test, pred)\n",
        "print(f\"Kappa Value: {kappa}\")\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "#Extra Tree Classifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "clf=ExtraTreesClassifier()\n",
        "clf.fit(x_train,y_train)\n",
        "ExtraTreesClassifier()\n",
        "pred=clf.predict(x_test)\n",
        "etc_score=clf.score(x_test,y_test)\n",
        "print(\"ETC_score= \",etc_score)\n",
        "from sklearn.metrics import r2_score\n",
        "r2_score= r2_score(y_test,pred)\n",
        "print(\"r2_score= \",r2_score)\n",
        "from sklearn.metrics import accuracy_score #accuracy check\n",
        "acaccury_score= accuracy_score(y_test,pred)\n",
        "print(\"Acaccury_score= \",acaccury_score)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn,fp,fn,tp= confusion_matrix(y_test,pred).ravel()\n",
        "sensitivity= tp/(tp+fn)\n",
        "specificity= tn/(tn+fp)\n",
        "print(f\"Sensitivity= {sensitivity}\")\n",
        "print(f\"Specificity= {specificity}\")\n",
        "from sklearn.metrics import matthews_corrcoef # Calculate Matthews Correlation Coefficient (MCC)\n",
        "mcc = matthews_corrcoef(y_test, pred)\n",
        "print(f\"MCC: {mcc}\")\n",
        "\n",
        "from sklearn.metrics import cohen_kappa_score # Calculate Kappa Value\n",
        "kappa = cohen_kappa_score(y_test, pred)\n",
        "print(f\"Kappa Value: {kappa}\")\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "#Gradient Boosting Classifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "clf=GradientBoostingClassifier()\n",
        "clf.fit(x_train,y_train)\n",
        "GradientBoostingClassifier()\n",
        "pred=clf.predict(x_test)\n",
        "gbc_score=clf.score(x_test,y_test)\n",
        "print(\"GBC_score= \",gbc_score)\n",
        "from sklearn.metrics import r2_score\n",
        "r2_score= r2_score(y_test,pred)\n",
        "print(\"r2_score= \",r2_score)\n",
        "from sklearn.metrics import accuracy_score #accuracy check\n",
        "acaccury_score= accuracy_score(y_test,pred)\n",
        "print(\"Acaccury_score= \",acaccury_score)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn,fp,fn,tp= confusion_matrix(y_test,pred).ravel()\n",
        "sensitivity= tp/(tp+fn)\n",
        "specificity= tn/(tn+fp)\n",
        "print(f\"Sensitivity= {sensitivity}\")\n",
        "print(f\"Specificity= {specificity}\")\n",
        "from sklearn.metrics import matthews_corrcoef # Calculate Matthews Correlation Coefficient (MCC)\n",
        "mcc = matthews_corrcoef(y_test, pred)\n",
        "print(f\"MCC: {mcc}\")\n",
        "\n",
        "from sklearn.metrics import cohen_kappa_score # Calculate Kappa Value\n",
        "kappa = cohen_kappa_score(y_test, pred)\n",
        "print(f\"Kappa Value: {kappa}\")\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7BsCbQstsxK",
        "outputId": "880ecff5-5f61-413f-fcad-fbb217a28dd8"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lin_score=  0.2482586293338659\n",
            "r2_score=  0.2482586293338659\n",
            "Acaccury_score=  0.7112676056338029\n",
            "Sensitivity= 0.717948717948718\n",
            "Specificity= 0.703125\n",
            "MCC: 0.4196888103559008\n",
            "Kappa Value: 0.419309794534211\n",
            "\n",
            "\n",
            "\n",
            "LR_score=  0.6408450704225352\n",
            "r2_score=  -0.45072115384615397\n",
            "Acaccury_score=  0.6408450704225352\n",
            "Sensitivity= 0.5256410256410257\n",
            "Specificity= 0.78125\n",
            "MCC: 0.31345882831648003\n",
            "Kappa Value: 0.29730254220842234\n",
            "\n",
            "\n",
            "\n",
            "DT_score=  0.5774647887323944\n",
            "r2_score=  -0.7067307692307694\n",
            "Acaccury_score=  0.5774647887323944\n",
            "Sensitivity= 0.6666666666666666\n",
            "Specificity= 0.46875\n",
            "MCC: 0.13786885490101272\n",
            "Kappa Value: 0.13695299837925445\n",
            "\n",
            "\n",
            "\n",
            "RF_score=  0.7605633802816901\n",
            "r2_score=  0.032852564102563986\n",
            "Acaccury_score=  0.7605633802816901\n",
            "Sensitivity= 0.782051282051282\n",
            "Specificity= 0.734375\n",
            "MCC: 0.516426282051282\n",
            "Kappa Value: 0.5164262820512822\n",
            "\n",
            "\n",
            "\n",
            "ETC_score=  0.7253521126760564\n",
            "r2_score=  -0.10937500000000022\n",
            "Acaccury_score=  0.7253521126760564\n",
            "Sensitivity= 0.7692307692307693\n",
            "Specificity= 0.671875\n",
            "MCC: 0.4433764271038151\n",
            "Kappa Value: 0.4429692214846107\n",
            "\n",
            "\n",
            "\n",
            "GBC_score=  0.6690140845070423\n",
            "r2_score=  -0.33693910256410264\n",
            "Acaccury_score=  0.6690140845070423\n",
            "Sensitivity= 0.6282051282051282\n",
            "Specificity= 0.71875\n",
            "MCC: 0.3458139959735586\n",
            "Kappa Value: 0.3416847504438746\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**DDE**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "__4flRSOuv-Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "df=pd.read_csv('/content/DDE  data.csv')\n",
        "# print(df.head(10))\n",
        "# print (df.isnull().any())\n",
        "x=df.drop('Target', axis=1)\n",
        "y=df['Target']\n",
        "x_train,x_test,y_train,y_test= train_test_split(x,y,test_size=0.30, random_state=10)\n",
        "\n",
        "#Linear Regression\n",
        "clf= LinearRegression()\n",
        "clf.fit(x_train,y_train)\n",
        "LinearRegression()\n",
        "pred=clf.predict(x_test)\n",
        "pred_labels = [round(value) for value in pred]\n",
        "\n",
        "lin_score= clf.score(x_test,y_test)\n",
        "print(\"Lin_score= \",lin_score)\n",
        "from sklearn.metrics import r2_score\n",
        "r2_score=r2_score(y_test,pred)\n",
        "print(\"r2_score= \",r2_score)\n",
        "from sklearn.metrics import accuracy_score #accuracy check\n",
        "acaccury_score= accuracy_score(y_test,pred_labels)\n",
        "print(\"Acaccury_score= \",acaccury_score)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn,fp,fn,tp= confusion_matrix(y_test,pred_labels).ravel()\n",
        "sensitivity= tp/(tp+fn)\n",
        "specificity= tn/(tn+fp)\n",
        "print(f\"Sensitivity= {sensitivity}\")\n",
        "print(f\"Specificity= {specificity}\")\n",
        "from sklearn.metrics import matthews_corrcoef # Calculate Matthews Correlation Coefficient (MCC)\n",
        "mcc = matthews_corrcoef(y_test, pred_labels)\n",
        "print(f\"MCC: {mcc}\")\n",
        "\n",
        "from sklearn.metrics import cohen_kappa_score # Calculate Kappa Value\n",
        "kappa = cohen_kappa_score(y_test, pred_labels)\n",
        "print(f\"Kappa Value: {kappa}\")\n",
        "\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "\n",
        "#Logistic Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "clf=LogisticRegression()\n",
        "clf.fit(x_train,y_train)\n",
        "LogisticRegression()\n",
        "pred=clf.predict(x_test)\n",
        "log_score=clf.score(x_test,y_test)\n",
        "print(\"LR_score= \",log_score)\n",
        "from sklearn.metrics import r2_score\n",
        "r2_score= r2_score(y_test,pred)\n",
        "print(\"r2_score= \",r2_score)\n",
        "from sklearn.metrics import accuracy_score #accuracy check\n",
        "acaccury_score= accuracy_score(y_test,pred)\n",
        "print(\"Acaccury_score= \",acaccury_score)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn,fp,fn,tp= confusion_matrix(y_test,pred).ravel()\n",
        "sensitivity= tp/(tp+fn)\n",
        "specificity= tn/(tn+fp)\n",
        "print(f\"Sensitivity= {sensitivity}\")\n",
        "print(f\"Specificity= {specificity}\")\n",
        "from sklearn.metrics import matthews_corrcoef # Calculate Matthews Correlation Coefficient (MCC)\n",
        "mcc = matthews_corrcoef(y_test, pred)\n",
        "print(f\"MCC: {mcc}\")\n",
        "\n",
        "from sklearn.metrics import cohen_kappa_score # Calculate Kappa Value\n",
        "kappa = cohen_kappa_score(y_test, pred)\n",
        "print(f\"Kappa Value: {kappa}\")\n",
        "\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "\n",
        "#Decision Tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "clf=DecisionTreeClassifier()\n",
        "clf.fit(x_train,y_train)\n",
        "DecisionTreeClassifier()\n",
        "pred=clf.predict(x_test)\n",
        "dt_score=clf.score(x_test,y_test)\n",
        "print(\"DT_score= \",dt_score)\n",
        "from sklearn.metrics import r2_score\n",
        "r2_score= r2_score(y_test,pred)\n",
        "print(\"r2_score= \",r2_score)\n",
        "from sklearn.metrics import accuracy_score #accuracy check\n",
        "acaccury_score= accuracy_score(y_test,pred)\n",
        "print(\"Acaccury_score= \",acaccury_score)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn,fp,fn,tp= confusion_matrix(y_test,pred).ravel()\n",
        "sensitivity= tp/(tp+fn)\n",
        "specificity= tn/(tn+fp)\n",
        "print(f\"Sensitivity= {sensitivity}\")\n",
        "print(f\"Specificity= {specificity}\")\n",
        "from sklearn.metrics import matthews_corrcoef # Calculate Matthews Correlation Coefficient (MCC)\n",
        "mcc = matthews_corrcoef(y_test, pred)\n",
        "print(f\"MCC: {mcc}\")\n",
        "\n",
        "from sklearn.metrics import cohen_kappa_score # Calculate Kappa Value\n",
        "kappa = cohen_kappa_score(y_test, pred)\n",
        "print(f\"Kappa Value: {kappa}\")\n",
        "print(\"\\n\\n\")\n",
        "# from sklearn import tree\n",
        "# tree.plot_tree(clf, filled=True, rounded=True, feature_names=x.columns)\n",
        "# plt.figure(figsize=(10,50))\n",
        "\n",
        "\n",
        "#Random Forest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "clf=RandomForestClassifier()\n",
        "clf.fit(x_train,y_train)\n",
        "RandomForestClassifier()\n",
        "pred=clf.predict(x_test)\n",
        "rf_score=clf.score(x_test,y_test)\n",
        "print(\"RF_score= \",rf_score)\n",
        "from sklearn.metrics import r2_score\n",
        "r2_score= r2_score(y_test,pred)\n",
        "print(\"r2_score= \",r2_score)\n",
        "from sklearn.metrics import accuracy_score #accuracy check\n",
        "acaccury_score= accuracy_score(y_test,pred)\n",
        "print(\"Acaccury_score= \",acaccury_score)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn,fp,fn,tp= confusion_matrix(y_test,pred).ravel()\n",
        "sensitivity= tp/(tp+fn)\n",
        "specificity= tn/(tn+fp)\n",
        "print(f\"Sensitivity= {sensitivity}\")\n",
        "print(f\"Specificity= {specificity}\")\n",
        "from sklearn.metrics import matthews_corrcoef # Calculate Matthews Correlation Coefficient (MCC)\n",
        "mcc = matthews_corrcoef(y_test, pred)\n",
        "print(f\"MCC: {mcc}\")\n",
        "\n",
        "from sklearn.metrics import cohen_kappa_score # Calculate Kappa Value\n",
        "kappa = cohen_kappa_score(y_test, pred)\n",
        "print(f\"Kappa Value: {kappa}\")\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "#Extra Tree Classifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "clf=ExtraTreesClassifier()\n",
        "clf.fit(x_train,y_train)\n",
        "ExtraTreesClassifier()\n",
        "pred=clf.predict(x_test)\n",
        "etc_score=clf.score(x_test,y_test)\n",
        "print(\"ETC_score= \",etc_score)\n",
        "from sklearn.metrics import r2_score\n",
        "r2_score= r2_score(y_test,pred)\n",
        "print(\"r2_score= \",r2_score)\n",
        "from sklearn.metrics import accuracy_score #accuracy check\n",
        "acaccury_score= accuracy_score(y_test,pred)\n",
        "print(\"Acaccury_score= \",acaccury_score)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn,fp,fn,tp= confusion_matrix(y_test,pred).ravel()\n",
        "sensitivity= tp/(tp+fn)\n",
        "specificity= tn/(tn+fp)\n",
        "print(f\"Sensitivity= {sensitivity}\")\n",
        "print(f\"Specificity= {specificity}\")\n",
        "from sklearn.metrics import matthews_corrcoef # Calculate Matthews Correlation Coefficient (MCC)\n",
        "mcc = matthews_corrcoef(y_test, pred)\n",
        "print(f\"MCC: {mcc}\")\n",
        "\n",
        "from sklearn.metrics import cohen_kappa_score # Calculate Kappa Value\n",
        "kappa = cohen_kappa_score(y_test, pred)\n",
        "print(f\"Kappa Value: {kappa}\")\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "#Gradient Boosting Classifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "clf=GradientBoostingClassifier()\n",
        "clf.fit(x_train,y_train)\n",
        "GradientBoostingClassifier()\n",
        "pred=clf.predict(x_test)\n",
        "gbc_score=clf.score(x_test,y_test)\n",
        "print(\"GBC_score= \",gbc_score)\n",
        "from sklearn.metrics import r2_score\n",
        "r2_score= r2_score(y_test,pred)\n",
        "print(\"r2_score= \",r2_score)\n",
        "from sklearn.metrics import accuracy_score #accuracy check\n",
        "acaccury_score= accuracy_score(y_test,pred)\n",
        "print(\"Acaccury_score= \",acaccury_score)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn,fp,fn,tp= confusion_matrix(y_test,pred).ravel()\n",
        "sensitivity= tp/(tp+fn)\n",
        "specificity= tn/(tn+fp)\n",
        "print(f\"Sensitivity= {sensitivity}\")\n",
        "print(f\"Specificity= {specificity}\")\n",
        "from sklearn.metrics import matthews_corrcoef # Calculate Matthews Correlation Coefficient (MCC)\n",
        "mcc = matthews_corrcoef(y_test, pred)\n",
        "print(f\"MCC: {mcc}\")\n",
        "\n",
        "from sklearn.metrics import cohen_kappa_score # Calculate Kappa Value\n",
        "kappa = cohen_kappa_score(y_test, pred)\n",
        "print(f\"Kappa Value: {kappa}\")\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "YRzy17nquwTS",
        "outputId": "8d3ca003-c13a-4481-d66b-d81e7824daad"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lin_score=  -2.312072464742372\n",
            "r2_score=  -2.312072464742372\n",
            "Acaccury_score=  0.4507042253521127\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-493cba35d8c9>\u001b[0m in \u001b[0;36m<cell line: 30>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Acaccury_score= \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0macaccury_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mtn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtp\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpred_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0msensitivity\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtp\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtp\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mspecificity\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtn\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtn\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 4)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**DPC**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "i1_nL3jlu6P2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "df=pd.read_csv('/content/DPC data.csv')\n",
        "# print(df.head(10))\n",
        "# print (df.isnull().any())\n",
        "x=df.drop('Target', axis=1)\n",
        "y=df['Target']\n",
        "x_train,x_test,y_train,y_test= train_test_split(x,y,test_size=0.30, random_state=11)\n",
        "\n",
        "#Linear Regression\n",
        "clf= LinearRegression()\n",
        "clf.fit(x_train,y_train)\n",
        "LinearRegression()\n",
        "pred=clf.predict(x_test)\n",
        "pred_labels = [round(value) for value in pred]\n",
        "\n",
        "lin_score= clf.score(x_test,y_test)\n",
        "print(\"Lin_score= \",lin_score)\n",
        "from sklearn.metrics import r2_score\n",
        "r2_score=r2_score(y_test,pred)\n",
        "print(\"r2_score= \",r2_score)\n",
        "from sklearn.metrics import accuracy_score #accuracy check\n",
        "acaccury_score= accuracy_score(y_test,pred_labels)\n",
        "print(\"Acaccury_score= \",acaccury_score)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn,fp,fn,tp= confusion_matrix(y_test,pred_labels).ravel()\n",
        "sensitivity= tp/(tp+fn)\n",
        "specificity= tn/(tn+fp)\n",
        "print(f\"Sensitivity= {sensitivity}\")\n",
        "print(f\"Specificity= {specificity}\")\n",
        "from sklearn.metrics import matthews_corrcoef # Calculate Matthews Correlation Coefficient (MCC)\n",
        "mcc = matthews_corrcoef(y_test, pred_labels)\n",
        "print(f\"MCC: {mcc}\")\n",
        "\n",
        "from sklearn.metrics import cohen_kappa_score # Calculate Kappa Value\n",
        "kappa = cohen_kappa_score(y_test, pred_labels)\n",
        "print(f\"Kappa Value: {kappa}\")\n",
        "\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "\n",
        "#Logistic Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "clf=LogisticRegression()\n",
        "clf.fit(x_train,y_train)\n",
        "LogisticRegression()\n",
        "pred=clf.predict(x_test)\n",
        "log_score=clf.score(x_test,y_test)\n",
        "print(\"LR_score= \",log_score)\n",
        "from sklearn.metrics import r2_score\n",
        "r2_score= r2_score(y_test,pred)\n",
        "print(\"r2_score= \",r2_score)\n",
        "from sklearn.metrics import accuracy_score #accuracy check\n",
        "acaccury_score= accuracy_score(y_test,pred)\n",
        "print(\"Acaccury_score= \",acaccury_score)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn,fp,fn,tp= confusion_matrix(y_test,pred).ravel()\n",
        "sensitivity= tp/(tp+fn)\n",
        "specificity= tn/(tn+fp)\n",
        "print(f\"Sensitivity= {sensitivity}\")\n",
        "print(f\"Specificity= {specificity}\")\n",
        "from sklearn.metrics import matthews_corrcoef # Calculate Matthews Correlation Coefficient (MCC)\n",
        "mcc = matthews_corrcoef(y_test, pred)\n",
        "print(f\"MCC: {mcc}\")\n",
        "\n",
        "from sklearn.metrics import cohen_kappa_score # Calculate Kappa Value\n",
        "kappa = cohen_kappa_score(y_test, pred)\n",
        "print(f\"Kappa Value: {kappa}\")\n",
        "\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "\n",
        "#Decision Tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "clf=DecisionTreeClassifier()\n",
        "clf.fit(x_train,y_train)\n",
        "DecisionTreeClassifier()\n",
        "pred=clf.predict(x_test)\n",
        "dt_score=clf.score(x_test,y_test)\n",
        "print(\"DT_score= \",dt_score)\n",
        "from sklearn.metrics import r2_score\n",
        "r2_score= r2_score(y_test,pred)\n",
        "print(\"r2_score= \",r2_score)\n",
        "from sklearn.metrics import accuracy_score #accuracy check\n",
        "acaccury_score= accuracy_score(y_test,pred)\n",
        "print(\"Acaccury_score= \",acaccury_score)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn,fp,fn,tp= confusion_matrix(y_test,pred).ravel()\n",
        "sensitivity= tp/(tp+fn)\n",
        "specificity= tn/(tn+fp)\n",
        "print(f\"Sensitivity= {sensitivity}\")\n",
        "print(f\"Specificity= {specificity}\")\n",
        "from sklearn.metrics import matthews_corrcoef # Calculate Matthews Correlation Coefficient (MCC)\n",
        "mcc = matthews_corrcoef(y_test, pred)\n",
        "print(f\"MCC: {mcc}\")\n",
        "\n",
        "from sklearn.metrics import cohen_kappa_score # Calculate Kappa Value\n",
        "kappa = cohen_kappa_score(y_test, pred)\n",
        "print(f\"Kappa Value: {kappa}\")\n",
        "print(\"\\n\\n\")\n",
        "# from sklearn import tree\n",
        "# tree.plot_tree(clf, filled=True, rounded=True, feature_names=x.columns)\n",
        "# plt.figure(figsize=(10,50))\n",
        "\n",
        "\n",
        "#Random Forest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "clf=RandomForestClassifier()\n",
        "clf.fit(x_train,y_train)\n",
        "RandomForestClassifier()\n",
        "pred=clf.predict(x_test)\n",
        "rf_score=clf.score(x_test,y_test)\n",
        "print(\"RF_score= \",rf_score)\n",
        "from sklearn.metrics import r2_score\n",
        "r2_score= r2_score(y_test,pred)\n",
        "print(\"r2_score= \",r2_score)\n",
        "from sklearn.metrics import accuracy_score #accuracy check\n",
        "acaccury_score= accuracy_score(y_test,pred)\n",
        "print(\"Acaccury_score= \",acaccury_score)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn,fp,fn,tp= confusion_matrix(y_test,pred).ravel()\n",
        "sensitivity= tp/(tp+fn)\n",
        "specificity= tn/(tn+fp)\n",
        "print(f\"Sensitivity= {sensitivity}\")\n",
        "print(f\"Specificity= {specificity}\")\n",
        "from sklearn.metrics import matthews_corrcoef # Calculate Matthews Correlation Coefficient (MCC)\n",
        "mcc = matthews_corrcoef(y_test, pred)\n",
        "print(f\"MCC: {mcc}\")\n",
        "\n",
        "from sklearn.metrics import cohen_kappa_score # Calculate Kappa Value\n",
        "kappa = cohen_kappa_score(y_test, pred)\n",
        "print(f\"Kappa Value: {kappa}\")\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "#Extra Tree Classifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "clf=ExtraTreesClassifier()\n",
        "clf.fit(x_train,y_train)\n",
        "ExtraTreesClassifier()\n",
        "pred=clf.predict(x_test)\n",
        "etc_score=clf.score(x_test,y_test)\n",
        "print(\"ETC_score= \",etc_score)\n",
        "from sklearn.metrics import r2_score\n",
        "r2_score= r2_score(y_test,pred)\n",
        "print(\"r2_score= \",r2_score)\n",
        "from sklearn.metrics import accuracy_score #accuracy check\n",
        "acaccury_score= accuracy_score(y_test,pred)\n",
        "print(\"Acaccury_score= \",acaccury_score)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn,fp,fn,tp= confusion_matrix(y_test,pred).ravel()\n",
        "sensitivity= tp/(tp+fn)\n",
        "specificity= tn/(tn+fp)\n",
        "print(f\"Sensitivity= {sensitivity}\")\n",
        "print(f\"Specificity= {specificity}\")\n",
        "from sklearn.metrics import matthews_corrcoef # Calculate Matthews Correlation Coefficient (MCC)\n",
        "mcc = matthews_corrcoef(y_test, pred)\n",
        "print(f\"MCC: {mcc}\")\n",
        "\n",
        "from sklearn.metrics import cohen_kappa_score # Calculate Kappa Value\n",
        "kappa = cohen_kappa_score(y_test, pred)\n",
        "print(f\"Kappa Value: {kappa}\")\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "#Gradient Boosting Classifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "clf=GradientBoostingClassifier()\n",
        "clf.fit(x_train,y_train)\n",
        "GradientBoostingClassifier()\n",
        "pred=clf.predict(x_test)\n",
        "gbc_score=clf.score(x_test,y_test)\n",
        "print(\"GBC_score= \",gbc_score)\n",
        "from sklearn.metrics import r2_score\n",
        "r2_score= r2_score(y_test,pred)\n",
        "print(\"r2_score= \",r2_score)\n",
        "from sklearn.metrics import accuracy_score #accuracy check\n",
        "acaccury_score= accuracy_score(y_test,pred)\n",
        "print(\"Acaccury_score= \",acaccury_score)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn,fp,fn,tp= confusion_matrix(y_test,pred).ravel()\n",
        "sensitivity= tp/(tp+fn)\n",
        "specificity= tn/(tn+fp)\n",
        "print(f\"Sensitivity= {sensitivity}\")\n",
        "print(f\"Specificity= {specificity}\")\n",
        "from sklearn.metrics import matthews_corrcoef # Calculate Matthews Correlation Coefficient (MCC)\n",
        "mcc = matthews_corrcoef(y_test, pred)\n",
        "print(f\"MCC: {mcc}\")\n",
        "\n",
        "from sklearn.metrics import cohen_kappa_score # Calculate Kappa Value\n",
        "kappa = cohen_kappa_score(y_test, pred)\n",
        "print(f\"Kappa Value: {kappa}\")\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "_lagbBpSu6gq",
        "outputId": "6cc672ec-82b4-439f-deb7-c57de66a1847"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lin_score=  -3.2061584944732084\n",
            "r2_score=  -3.2061584944732084\n",
            "Acaccury_score=  0.323943661971831\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-69-97123dc73bfe>\u001b[0m in \u001b[0;36m<cell line: 30>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Acaccury_score= \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0macaccury_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mtn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtp\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpred_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0msensitivity\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtp\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtp\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mspecificity\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtn\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtn\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 4)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**GAAC**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "5zEitxKgu6oW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "df=pd.read_csv('/content/GAAC data.csv')\n",
        "# print(df.head(10))\n",
        "# print (df.isnull().any())\n",
        "x=df.drop('Target', axis=1)\n",
        "y=df['Target']\n",
        "x_train,x_test,y_train,y_test= train_test_split(x,y,test_size=0.30, random_state=8)\n",
        "\n",
        "#Linear Regression\n",
        "clf= LinearRegression()\n",
        "clf.fit(x_train,y_train)\n",
        "LinearRegression()\n",
        "pred=clf.predict(x_test)\n",
        "pred_labels = [round(value) for value in pred]\n",
        "\n",
        "lin_score= clf.score(x_test,y_test)\n",
        "print(\"Lin_score= \",lin_score)\n",
        "from sklearn.metrics import r2_score\n",
        "r2_score=r2_score(y_test,pred)\n",
        "print(\"r2_score= \",r2_score)\n",
        "from sklearn.metrics import accuracy_score #accuracy check\n",
        "acaccury_score= accuracy_score(y_test,pred_labels)\n",
        "print(\"Acaccury_score= \",acaccury_score)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn,fp,fn,tp= confusion_matrix(y_test,pred_labels).ravel()\n",
        "sensitivity= tp/(tp+fn)\n",
        "specificity= tn/(tn+fp)\n",
        "print(f\"Sensitivity= {sensitivity}\")\n",
        "print(f\"Specificity= {specificity}\")\n",
        "from sklearn.metrics import matthews_corrcoef # Calculate Matthews Correlation Coefficient (MCC)\n",
        "mcc = matthews_corrcoef(y_test, pred_labels)\n",
        "print(f\"MCC: {mcc}\")\n",
        "\n",
        "from sklearn.metrics import cohen_kappa_score # Calculate Kappa Value\n",
        "kappa = cohen_kappa_score(y_test, pred_labels)\n",
        "print(f\"Kappa Value: {kappa}\")\n",
        "\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "\n",
        "#Logistic Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "clf=LogisticRegression()\n",
        "clf.fit(x_train,y_train)\n",
        "LogisticRegression()\n",
        "pred=clf.predict(x_test)\n",
        "log_score=clf.score(x_test,y_test)\n",
        "print(\"LR_score= \",log_score)\n",
        "from sklearn.metrics import r2_score\n",
        "r2_score= r2_score(y_test,pred)\n",
        "print(\"r2_score= \",r2_score)\n",
        "from sklearn.metrics import accuracy_score #accuracy check\n",
        "acaccury_score= accuracy_score(y_test,pred)\n",
        "print(\"Acaccury_score= \",acaccury_score)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn,fp,fn,tp= confusion_matrix(y_test,pred).ravel()\n",
        "sensitivity= tp/(tp+fn)\n",
        "specificity= tn/(tn+fp)\n",
        "print(f\"Sensitivity= {sensitivity}\")\n",
        "print(f\"Specificity= {specificity}\")\n",
        "from sklearn.metrics import matthews_corrcoef # Calculate Matthews Correlation Coefficient (MCC)\n",
        "mcc = matthews_corrcoef(y_test, pred)\n",
        "print(f\"MCC: {mcc}\")\n",
        "\n",
        "from sklearn.metrics import cohen_kappa_score # Calculate Kappa Value\n",
        "kappa = cohen_kappa_score(y_test, pred)\n",
        "print(f\"Kappa Value: {kappa}\")\n",
        "\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "\n",
        "#Decision Tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "clf=DecisionTreeClassifier()\n",
        "clf.fit(x_train,y_train)\n",
        "DecisionTreeClassifier()\n",
        "pred=clf.predict(x_test)\n",
        "dt_score=clf.score(x_test,y_test)\n",
        "print(\"DT_score= \",dt_score)\n",
        "from sklearn.metrics import r2_score\n",
        "r2_score= r2_score(y_test,pred)\n",
        "print(\"r2_score= \",r2_score)\n",
        "from sklearn.metrics import accuracy_score #accuracy check\n",
        "acaccury_score= accuracy_score(y_test,pred)\n",
        "print(\"Acaccury_score= \",acaccury_score)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn,fp,fn,tp= confusion_matrix(y_test,pred).ravel()\n",
        "sensitivity= tp/(tp+fn)\n",
        "specificity= tn/(tn+fp)\n",
        "print(f\"Sensitivity= {sensitivity}\")\n",
        "print(f\"Specificity= {specificity}\")\n",
        "from sklearn.metrics import matthews_corrcoef # Calculate Matthews Correlation Coefficient (MCC)\n",
        "mcc = matthews_corrcoef(y_test, pred)\n",
        "print(f\"MCC: {mcc}\")\n",
        "\n",
        "from sklearn.metrics import cohen_kappa_score # Calculate Kappa Value\n",
        "kappa = cohen_kappa_score(y_test, pred)\n",
        "print(f\"Kappa Value: {kappa}\")\n",
        "print(\"\\n\\n\")\n",
        "# from sklearn import tree\n",
        "# tree.plot_tree(clf, filled=True, rounded=True, feature_names=x.columns)\n",
        "# plt.figure(figsize=(10,50))\n",
        "\n",
        "\n",
        "#Random Forest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "clf=RandomForestClassifier()\n",
        "clf.fit(x_train,y_train)\n",
        "RandomForestClassifier()\n",
        "pred=clf.predict(x_test)\n",
        "rf_score=clf.score(x_test,y_test)\n",
        "print(\"RF_score= \",rf_score)\n",
        "from sklearn.metrics import r2_score\n",
        "r2_score= r2_score(y_test,pred)\n",
        "print(\"r2_score= \",r2_score)\n",
        "from sklearn.metrics import accuracy_score #accuracy check\n",
        "acaccury_score= accuracy_score(y_test,pred)\n",
        "print(\"Acaccury_score= \",acaccury_score)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn,fp,fn,tp= confusion_matrix(y_test,pred).ravel()\n",
        "sensitivity= tp/(tp+fn)\n",
        "specificity= tn/(tn+fp)\n",
        "print(f\"Sensitivity= {sensitivity}\")\n",
        "print(f\"Specificity= {specificity}\")\n",
        "from sklearn.metrics import matthews_corrcoef # Calculate Matthews Correlation Coefficient (MCC)\n",
        "mcc = matthews_corrcoef(y_test, pred)\n",
        "print(f\"MCC: {mcc}\")\n",
        "\n",
        "from sklearn.metrics import cohen_kappa_score # Calculate Kappa Value\n",
        "kappa = cohen_kappa_score(y_test, pred)\n",
        "print(f\"Kappa Value: {kappa}\")\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "#Extra Tree Classifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "clf=ExtraTreesClassifier()\n",
        "clf.fit(x_train,y_train)\n",
        "ExtraTreesClassifier()\n",
        "pred=clf.predict(x_test)\n",
        "etc_score=clf.score(x_test,y_test)\n",
        "print(\"ETC_score= \",etc_score)\n",
        "from sklearn.metrics import r2_score\n",
        "r2_score= r2_score(y_test,pred)\n",
        "print(\"r2_score= \",r2_score)\n",
        "from sklearn.metrics import accuracy_score #accuracy check\n",
        "acaccury_score= accuracy_score(y_test,pred)\n",
        "print(\"Acaccury_score= \",acaccury_score)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn,fp,fn,tp= confusion_matrix(y_test,pred).ravel()\n",
        "sensitivity= tp/(tp+fn)\n",
        "specificity= tn/(tn+fp)\n",
        "print(f\"Sensitivity= {sensitivity}\")\n",
        "print(f\"Specificity= {specificity}\")\n",
        "from sklearn.metrics import matthews_corrcoef # Calculate Matthews Correlation Coefficient (MCC)\n",
        "mcc = matthews_corrcoef(y_test, pred)\n",
        "print(f\"MCC: {mcc}\")\n",
        "\n",
        "from sklearn.metrics import cohen_kappa_score # Calculate Kappa Value\n",
        "kappa = cohen_kappa_score(y_test, pred)\n",
        "print(f\"Kappa Value: {kappa}\")\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "#Gradient Boosting Classifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "clf=GradientBoostingClassifier()\n",
        "clf.fit(x_train,y_train)\n",
        "GradientBoostingClassifier()\n",
        "pred=clf.predict(x_test)\n",
        "gbc_score=clf.score(x_test,y_test)\n",
        "print(\"GBC_score= \",gbc_score)\n",
        "from sklearn.metrics import r2_score\n",
        "r2_score= r2_score(y_test,pred)\n",
        "print(\"r2_score= \",r2_score)\n",
        "from sklearn.metrics import accuracy_score #accuracy check\n",
        "acaccury_score= accuracy_score(y_test,pred)\n",
        "print(\"Acaccury_score= \",acaccury_score)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn,fp,fn,tp= confusion_matrix(y_test,pred).ravel()\n",
        "sensitivity= tp/(tp+fn)\n",
        "specificity= tn/(tn+fp)\n",
        "print(f\"Sensitivity= {sensitivity}\")\n",
        "print(f\"Specificity= {specificity}\")\n",
        "from sklearn.metrics import matthews_corrcoef # Calculate Matthews Correlation Coefficient (MCC)\n",
        "mcc = matthews_corrcoef(y_test, pred)\n",
        "print(f\"MCC: {mcc}\")\n",
        "\n",
        "from sklearn.metrics import cohen_kappa_score # Calculate Kappa Value\n",
        "kappa = cohen_kappa_score(y_test, pred)\n",
        "print(f\"Kappa Value: {kappa}\")\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4qIgwEOeu6xw",
        "outputId": "1563b22e-7ed3-4f16-b4ac-eb1f920c4f4f"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lin_score=  0.07761863720232587\n",
            "r2_score=  0.07761863720232587\n",
            "Acaccury_score=  0.6126760563380281\n",
            "Sensitivity= 0.6666666666666666\n",
            "Specificity= 0.5571428571428572\n",
            "MCC: 0.22522158528620473\n",
            "Kappa Value: 0.22412080270216572\n",
            "\n",
            "\n",
            "\n",
            "LR_score=  0.5633802816901409\n",
            "r2_score=  -0.7468253968253966\n",
            "Acaccury_score=  0.5633802816901409\n",
            "Sensitivity= 0.6111111111111112\n",
            "Specificity= 0.5142857142857142\n",
            "MCC: 0.12599825247026097\n",
            "Kappa Value: 0.12554628526023037\n",
            "\n",
            "\n",
            "\n",
            "DT_score=  0.5704225352112676\n",
            "r2_score=  -0.7186507936507933\n",
            "Acaccury_score=  0.5704225352112676\n",
            "Sensitivity= 0.5277777777777778\n",
            "Specificity= 0.6142857142857143\n",
            "MCC: 0.1425593521821612\n",
            "Kappa Value: 0.1418664553199921\n",
            "\n",
            "\n",
            "\n",
            "RF_score=  0.5985915492957746\n",
            "r2_score=  -0.6059523809523806\n",
            "Acaccury_score=  0.5985915492957746\n",
            "Sensitivity= 0.5555555555555556\n",
            "Specificity= 0.6428571428571429\n",
            "MCC: 0.19910524047787875\n",
            "Kappa Value: 0.19813750743015657\n",
            "\n",
            "\n",
            "\n",
            "ETC_score=  0.5985915492957746\n",
            "r2_score=  -0.6059523809523806\n",
            "Acaccury_score=  0.5985915492957746\n",
            "Sensitivity= 0.6111111111111112\n",
            "Specificity= 0.5857142857142857\n",
            "MCC: 0.19688400197685943\n",
            "Kappa Value: 0.19686445723357804\n",
            "\n",
            "\n",
            "\n",
            "GBC_score=  0.6197183098591549\n",
            "r2_score=  -0.5214285714285711\n",
            "Acaccury_score=  0.6197183098591549\n",
            "Sensitivity= 0.6111111111111112\n",
            "Specificity= 0.6285714285714286\n",
            "MCC: 0.2396825396825397\n",
            "Kappa Value: 0.23958746529155095\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**MORAN**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "lcZBZno3u6-a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "df=pd.read_csv('/content/Moran data.csv')\n",
        "# print(df.head(10))\n",
        "# print (df.isnull().any())\n",
        "x=df.drop('Target', axis=1)\n",
        "y=df['Target']\n",
        "x_train,x_test,y_train,y_test= train_test_split(x,y,test_size=0.30, random_state=8)\n",
        "\n",
        "#Linear Regression\n",
        "clf= LinearRegression()\n",
        "clf.fit(x_train,y_train)\n",
        "LinearRegression()\n",
        "pred=clf.predict(x_test)\n",
        "pred_labels = [round(value) for value in pred]\n",
        "\n",
        "lin_score= clf.score(x_test,y_test)\n",
        "print(\"Lin_score= \",lin_score)\n",
        "from sklearn.metrics import r2_score\n",
        "r2_score=r2_score(y_test,pred)\n",
        "print(\"r2_score= \",r2_score)\n",
        "from sklearn.metrics import accuracy_score #accuracy check\n",
        "acaccury_score= accuracy_score(y_test,pred_labels)\n",
        "print(\"Acaccury_score= \",acaccury_score)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn,fp,fn,tp= confusion_matrix(y_test,pred_labels).ravel()\n",
        "sensitivity= tp/(tp+fn)\n",
        "specificity= tn/(tn+fp)\n",
        "print(f\"Sensitivity= {sensitivity}\")\n",
        "print(f\"Specificity= {specificity}\")\n",
        "from sklearn.metrics import matthews_corrcoef # Calculate Matthews Correlation Coefficient (MCC)\n",
        "mcc = matthews_corrcoef(y_test, pred_labels)\n",
        "print(f\"MCC: {mcc}\")\n",
        "\n",
        "from sklearn.metrics import cohen_kappa_score # Calculate Kappa Value\n",
        "kappa = cohen_kappa_score(y_test, pred_labels)\n",
        "print(f\"Kappa Value: {kappa}\")\n",
        "\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "\n",
        "#Logistic Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "clf=LogisticRegression()\n",
        "clf.fit(x_train,y_train)\n",
        "LogisticRegression()\n",
        "pred=clf.predict(x_test)\n",
        "log_score=clf.score(x_test,y_test)\n",
        "print(\"LR_score= \",log_score)\n",
        "from sklearn.metrics import r2_score\n",
        "r2_score= r2_score(y_test,pred)\n",
        "print(\"r2_score= \",r2_score)\n",
        "from sklearn.metrics import accuracy_score #accuracy check\n",
        "acaccury_score= accuracy_score(y_test,pred)\n",
        "print(\"Acaccury_score= \",acaccury_score)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn,fp,fn,tp= confusion_matrix(y_test,pred).ravel()\n",
        "sensitivity= tp/(tp+fn)\n",
        "specificity= tn/(tn+fp)\n",
        "print(f\"Sensitivity= {sensitivity}\")\n",
        "print(f\"Specificity= {specificity}\")\n",
        "from sklearn.metrics import matthews_corrcoef # Calculate Matthews Correlation Coefficient (MCC)\n",
        "mcc = matthews_corrcoef(y_test, pred)\n",
        "print(f\"MCC: {mcc}\")\n",
        "\n",
        "from sklearn.metrics import cohen_kappa_score # Calculate Kappa Value\n",
        "kappa = cohen_kappa_score(y_test, pred)\n",
        "print(f\"Kappa Value: {kappa}\")\n",
        "\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "\n",
        "#Decision Tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "clf=DecisionTreeClassifier()\n",
        "clf.fit(x_train,y_train)\n",
        "DecisionTreeClassifier()\n",
        "pred=clf.predict(x_test)\n",
        "dt_score=clf.score(x_test,y_test)\n",
        "print(\"DT_score= \",dt_score)\n",
        "from sklearn.metrics import r2_score\n",
        "r2_score= r2_score(y_test,pred)\n",
        "print(\"r2_score= \",r2_score)\n",
        "from sklearn.metrics import accuracy_score #accuracy check\n",
        "acaccury_score= accuracy_score(y_test,pred)\n",
        "print(\"Acaccury_score= \",acaccury_score)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn,fp,fn,tp= confusion_matrix(y_test,pred).ravel()\n",
        "sensitivity= tp/(tp+fn)\n",
        "specificity= tn/(tn+fp)\n",
        "print(f\"Sensitivity= {sensitivity}\")\n",
        "print(f\"Specificity= {specificity}\")\n",
        "from sklearn.metrics import matthews_corrcoef # Calculate Matthews Correlation Coefficient (MCC)\n",
        "mcc = matthews_corrcoef(y_test, pred)\n",
        "print(f\"MCC: {mcc}\")\n",
        "\n",
        "from sklearn.metrics import cohen_kappa_score # Calculate Kappa Value\n",
        "kappa = cohen_kappa_score(y_test, pred)\n",
        "print(f\"Kappa Value: {kappa}\")\n",
        "print(\"\\n\\n\")\n",
        "# from sklearn import tree\n",
        "# tree.plot_tree(clf, filled=True, rounded=True, feature_names=x.columns)\n",
        "# plt.figure(figsize=(10,50))\n",
        "\n",
        "\n",
        "#Random Forest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "clf=RandomForestClassifier()\n",
        "clf.fit(x_train,y_train)\n",
        "RandomForestClassifier()\n",
        "pred=clf.predict(x_test)\n",
        "rf_score=clf.score(x_test,y_test)\n",
        "print(\"RF_score= \",rf_score)\n",
        "from sklearn.metrics import r2_score\n",
        "r2_score= r2_score(y_test,pred)\n",
        "print(\"r2_score= \",r2_score)\n",
        "from sklearn.metrics import accuracy_score #accuracy check\n",
        "acaccury_score= accuracy_score(y_test,pred)\n",
        "print(\"Acaccury_score= \",acaccury_score)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn,fp,fn,tp= confusion_matrix(y_test,pred).ravel()\n",
        "sensitivity= tp/(tp+fn)\n",
        "specificity= tn/(tn+fp)\n",
        "print(f\"Sensitivity= {sensitivity}\")\n",
        "print(f\"Specificity= {specificity}\")\n",
        "from sklearn.metrics import matthews_corrcoef # Calculate Matthews Correlation Coefficient (MCC)\n",
        "mcc = matthews_corrcoef(y_test, pred)\n",
        "print(f\"MCC: {mcc}\")\n",
        "\n",
        "from sklearn.metrics import cohen_kappa_score # Calculate Kappa Value\n",
        "kappa = cohen_kappa_score(y_test, pred)\n",
        "print(f\"Kappa Value: {kappa}\")\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "#Extra Tree Classifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "clf=ExtraTreesClassifier()\n",
        "clf.fit(x_train,y_train)\n",
        "ExtraTreesClassifier()\n",
        "pred=clf.predict(x_test)\n",
        "etc_score=clf.score(x_test,y_test)\n",
        "print(\"ETC_score= \",etc_score)\n",
        "from sklearn.metrics import r2_score\n",
        "r2_score= r2_score(y_test,pred)\n",
        "print(\"r2_score= \",r2_score)\n",
        "from sklearn.metrics import accuracy_score #accuracy check\n",
        "acaccury_score= accuracy_score(y_test,pred)\n",
        "print(\"Acaccury_score= \",acaccury_score)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn,fp,fn,tp= confusion_matrix(y_test,pred).ravel()\n",
        "sensitivity= tp/(tp+fn)\n",
        "specificity= tn/(tn+fp)\n",
        "print(f\"Sensitivity= {sensitivity}\")\n",
        "print(f\"Specificity= {specificity}\")\n",
        "from sklearn.metrics import matthews_corrcoef # Calculate Matthews Correlation Coefficient (MCC)\n",
        "mcc = matthews_corrcoef(y_test, pred)\n",
        "print(f\"MCC: {mcc}\")\n",
        "\n",
        "from sklearn.metrics import cohen_kappa_score # Calculate Kappa Value\n",
        "kappa = cohen_kappa_score(y_test, pred)\n",
        "print(f\"Kappa Value: {kappa}\")\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "#Gradient Boosting Classifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "clf=GradientBoostingClassifier()\n",
        "clf.fit(x_train,y_train)\n",
        "GradientBoostingClassifier()\n",
        "pred=clf.predict(x_test)\n",
        "gbc_score=clf.score(x_test,y_test)\n",
        "print(\"GBC_score= \",gbc_score)\n",
        "from sklearn.metrics import r2_score\n",
        "r2_score= r2_score(y_test,pred)\n",
        "print(\"r2_score= \",r2_score)\n",
        "from sklearn.metrics import accuracy_score #accuracy check\n",
        "acaccury_score= accuracy_score(y_test,pred)\n",
        "print(\"Acaccury_score= \",acaccury_score)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn,fp,fn,tp= confusion_matrix(y_test,pred).ravel()\n",
        "sensitivity= tp/(tp+fn)\n",
        "specificity= tn/(tn+fp)\n",
        "print(f\"Sensitivity= {sensitivity}\")\n",
        "print(f\"Specificity= {specificity}\")\n",
        "from sklearn.metrics import matthews_corrcoef # Calculate Matthews Correlation Coefficient (MCC)\n",
        "mcc = matthews_corrcoef(y_test, pred)\n",
        "print(f\"MCC: {mcc}\")\n",
        "\n",
        "from sklearn.metrics import cohen_kappa_score # Calculate Kappa Value\n",
        "kappa = cohen_kappa_score(y_test, pred)\n",
        "print(f\"Kappa Value: {kappa}\")\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xd8boEOJu7KU",
        "outputId": "f8c38a3c-3ab3-416e-d721-7c48781e799e"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lin_score=  -0.03339053034147321\n",
            "r2_score=  -0.03339053034147321\n",
            "Acaccury_score=  0.5211267605633803\n",
            "Sensitivity= 0.5555555555555556\n",
            "Specificity= 0.4857142857142857\n",
            "MCC: 0.04136845512912142\n",
            "Kappa Value: 0.0413026211278793\n",
            "\n",
            "\n",
            "\n",
            "LR_score=  0.5352112676056338\n",
            "r2_score=  -0.8595238095238091\n",
            "Acaccury_score=  0.5352112676056338\n",
            "Sensitivity= 0.5416666666666666\n",
            "Specificity= 0.5285714285714286\n",
            "MCC: 0.07023809523809524\n",
            "Kappa Value: 0.07023809523809521\n",
            "\n",
            "\n",
            "\n",
            "DT_score=  0.5704225352112676\n",
            "r2_score=  -0.7186507936507933\n",
            "Acaccury_score=  0.5704225352112676\n",
            "Sensitivity= 0.6805555555555556\n",
            "Specificity= 0.45714285714285713\n",
            "MCC: 0.14131987062467471\n",
            "Kappa Value: 0.13810945273631836\n",
            "\n",
            "\n",
            "\n",
            "RF_score=  0.6126760563380281\n",
            "r2_score=  -0.5496031746031744\n",
            "Acaccury_score=  0.6126760563380281\n",
            "Sensitivity= 0.6111111111111112\n",
            "Specificity= 0.6142857142857143\n",
            "MCC: 0.22537446792760443\n",
            "Kappa Value: 0.22535211267605637\n",
            "\n",
            "\n",
            "\n",
            "ETC_score=  0.5915492957746479\n",
            "r2_score=  -0.6341269841269839\n",
            "Acaccury_score=  0.5915492957746479\n",
            "Sensitivity= 0.5833333333333334\n",
            "Specificity= 0.6\n",
            "MCC: 0.18333333333333332\n",
            "Kappa Value: 0.18326061086870293\n",
            "\n",
            "\n",
            "\n",
            "GBC_score=  0.5211267605633803\n",
            "r2_score=  -0.9158730158730155\n",
            "Acaccury_score=  0.5211267605633803\n",
            "Sensitivity= 0.5277777777777778\n",
            "Specificity= 0.5142857142857142\n",
            "MCC: 0.04206349206349207\n",
            "Kappa Value: 0.042063492063492025\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**PAAC**:\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "zlaGjCHGu7Sy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "df=pd.read_csv('/content/PAAC data.csv')\n",
        "# print(df.head(10))\n",
        "# print (df.isnull().any())\n",
        "x=df.drop('Target', axis=1)\n",
        "y=df['Target']\n",
        "x_train,x_test,y_train,y_test= train_test_split(x,y,test_size=0.30, random_state=8)\n",
        "\n",
        "#Linear Regression\n",
        "clf= LinearRegression()\n",
        "clf.fit(x_train,y_train)\n",
        "LinearRegression()\n",
        "pred=clf.predict(x_test)\n",
        "pred_labels = [round(value) for value in pred]\n",
        "\n",
        "lin_score= clf.score(x_test,y_test)\n",
        "print(\"Lin_score= \",lin_score)\n",
        "from sklearn.metrics import r2_score\n",
        "r2_score=r2_score(y_test,pred)\n",
        "print(\"r2_score= \",r2_score)\n",
        "from sklearn.metrics import accuracy_score #accuracy check\n",
        "acaccury_score= accuracy_score(y_test,pred_labels)\n",
        "print(\"Acaccury_score= \",acaccury_score)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn,fp,fn,tp= confusion_matrix(y_test,pred_labels).ravel()\n",
        "sensitivity= tp/(tp+fn)\n",
        "specificity= tn/(tn+fp)\n",
        "print(f\"Sensitivity= {sensitivity}\")\n",
        "print(f\"Specificity= {specificity}\")\n",
        "from sklearn.metrics import matthews_corrcoef # Calculate Matthews Correlation Coefficient (MCC)\n",
        "mcc = matthews_corrcoef(y_test, pred_labels)\n",
        "print(f\"MCC: {mcc}\")\n",
        "\n",
        "from sklearn.metrics import cohen_kappa_score # Calculate Kappa Value\n",
        "kappa = cohen_kappa_score(y_test, pred_labels)\n",
        "print(f\"Kappa Value: {kappa}\")\n",
        "\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "\n",
        "#Logistic Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "clf=LogisticRegression()\n",
        "clf.fit(x_train,y_train)\n",
        "LogisticRegression()\n",
        "pred=clf.predict(x_test)\n",
        "log_score=clf.score(x_test,y_test)\n",
        "print(\"LR_score= \",log_score)\n",
        "from sklearn.metrics import r2_score\n",
        "r2_score= r2_score(y_test,pred)\n",
        "print(\"r2_score= \",r2_score)\n",
        "from sklearn.metrics import accuracy_score #accuracy check\n",
        "acaccury_score= accuracy_score(y_test,pred)\n",
        "print(\"Acaccury_score= \",acaccury_score)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn,fp,fn,tp= confusion_matrix(y_test,pred).ravel()\n",
        "sensitivity= tp/(tp+fn)\n",
        "specificity= tn/(tn+fp)\n",
        "print(f\"Sensitivity= {sensitivity}\")\n",
        "print(f\"Specificity= {specificity}\")\n",
        "from sklearn.metrics import matthews_corrcoef # Calculate Matthews Correlation Coefficient (MCC)\n",
        "mcc = matthews_corrcoef(y_test, pred)\n",
        "print(f\"MCC: {mcc}\")\n",
        "\n",
        "from sklearn.metrics import cohen_kappa_score # Calculate Kappa Value\n",
        "kappa = cohen_kappa_score(y_test, pred)\n",
        "print(f\"Kappa Value: {kappa}\")\n",
        "\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "\n",
        "#Decision Tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "clf=DecisionTreeClassifier()\n",
        "clf.fit(x_train,y_train)\n",
        "DecisionTreeClassifier()\n",
        "pred=clf.predict(x_test)\n",
        "dt_score=clf.score(x_test,y_test)\n",
        "print(\"DT_score= \",dt_score)\n",
        "from sklearn.metrics import r2_score\n",
        "r2_score= r2_score(y_test,pred)\n",
        "print(\"r2_score= \",r2_score)\n",
        "from sklearn.metrics import accuracy_score #accuracy check\n",
        "acaccury_score= accuracy_score(y_test,pred)\n",
        "print(\"Acaccury_score= \",acaccury_score)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn,fp,fn,tp= confusion_matrix(y_test,pred).ravel()\n",
        "sensitivity= tp/(tp+fn)\n",
        "specificity= tn/(tn+fp)\n",
        "print(f\"Sensitivity= {sensitivity}\")\n",
        "print(f\"Specificity= {specificity}\")\n",
        "from sklearn.metrics import matthews_corrcoef # Calculate Matthews Correlation Coefficient (MCC)\n",
        "mcc = matthews_corrcoef(y_test, pred)\n",
        "print(f\"MCC: {mcc}\")\n",
        "\n",
        "from sklearn.metrics import cohen_kappa_score # Calculate Kappa Value\n",
        "kappa = cohen_kappa_score(y_test, pred)\n",
        "print(f\"Kappa Value: {kappa}\")\n",
        "print(\"\\n\\n\")\n",
        "# from sklearn import tree\n",
        "# tree.plot_tree(clf, filled=True, rounded=True, feature_names=x.columns)\n",
        "# plt.figure(figsize=(10,50))\n",
        "\n",
        "\n",
        "#Random Forest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "clf=RandomForestClassifier()\n",
        "clf.fit(x_train,y_train)\n",
        "RandomForestClassifier()\n",
        "pred=clf.predict(x_test)\n",
        "rf_score=clf.score(x_test,y_test)\n",
        "print(\"RF_score= \",rf_score)\n",
        "from sklearn.metrics import r2_score\n",
        "r2_score= r2_score(y_test,pred)\n",
        "print(\"r2_score= \",r2_score)\n",
        "from sklearn.metrics import accuracy_score #accuracy check\n",
        "acaccury_score= accuracy_score(y_test,pred)\n",
        "print(\"Acaccury_score= \",acaccury_score)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn,fp,fn,tp= confusion_matrix(y_test,pred).ravel()\n",
        "sensitivity= tp/(tp+fn)\n",
        "specificity= tn/(tn+fp)\n",
        "print(f\"Sensitivity= {sensitivity}\")\n",
        "print(f\"Specificity= {specificity}\")\n",
        "from sklearn.metrics import matthews_corrcoef # Calculate Matthews Correlation Coefficient (MCC)\n",
        "mcc = matthews_corrcoef(y_test, pred)\n",
        "print(f\"MCC: {mcc}\")\n",
        "\n",
        "from sklearn.metrics import cohen_kappa_score # Calculate Kappa Value\n",
        "kappa = cohen_kappa_score(y_test, pred)\n",
        "print(f\"Kappa Value: {kappa}\")\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "#Extra Tree Classifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "clf=ExtraTreesClassifier()\n",
        "clf.fit(x_train,y_train)\n",
        "ExtraTreesClassifier()\n",
        "pred=clf.predict(x_test)\n",
        "etc_score=clf.score(x_test,y_test)\n",
        "print(\"ETC_score= \",etc_score)\n",
        "from sklearn.metrics import r2_score\n",
        "r2_score= r2_score(y_test,pred)\n",
        "print(\"r2_score= \",r2_score)\n",
        "from sklearn.metrics import accuracy_score #accuracy check\n",
        "acaccury_score= accuracy_score(y_test,pred)\n",
        "print(\"Acaccury_score= \",acaccury_score)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn,fp,fn,tp= confusion_matrix(y_test,pred).ravel()\n",
        "sensitivity= tp/(tp+fn)\n",
        "specificity= tn/(tn+fp)\n",
        "print(f\"Sensitivity= {sensitivity}\")\n",
        "print(f\"Specificity= {specificity}\")\n",
        "from sklearn.metrics import matthews_corrcoef # Calculate Matthews Correlation Coefficient (MCC)\n",
        "mcc = matthews_corrcoef(y_test, pred)\n",
        "print(f\"MCC: {mcc}\")\n",
        "\n",
        "from sklearn.metrics import cohen_kappa_score # Calculate Kappa Value\n",
        "kappa = cohen_kappa_score(y_test, pred)\n",
        "print(f\"Kappa Value: {kappa}\")\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "#Gradient Boosting Classifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "clf=GradientBoostingClassifier()\n",
        "clf.fit(x_train,y_train)\n",
        "GradientBoostingClassifier()\n",
        "pred=clf.predict(x_test)\n",
        "gbc_score=clf.score(x_test,y_test)\n",
        "print(\"GBC_score= \",gbc_score)\n",
        "from sklearn.metrics import r2_score\n",
        "r2_score= r2_score(y_test,pred)\n",
        "print(\"r2_score= \",r2_score)\n",
        "from sklearn.metrics import accuracy_score #accuracy check\n",
        "acaccury_score= accuracy_score(y_test,pred)\n",
        "print(\"Acaccury_score= \",acaccury_score)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn,fp,fn,tp= confusion_matrix(y_test,pred).ravel()\n",
        "sensitivity= tp/(tp+fn)\n",
        "specificity= tn/(tn+fp)\n",
        "print(f\"Sensitivity= {sensitivity}\")\n",
        "print(f\"Specificity= {specificity}\")\n",
        "from sklearn.metrics import matthews_corrcoef # Calculate Matthews Correlation Coefficient (MCC)\n",
        "mcc = matthews_corrcoef(y_test, pred)\n",
        "print(f\"MCC: {mcc}\")\n",
        "\n",
        "from sklearn.metrics import cohen_kappa_score # Calculate Kappa Value\n",
        "kappa = cohen_kappa_score(y_test, pred)\n",
        "print(f\"Kappa Value: {kappa}\")\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJCHyLIRu7bO",
        "outputId": "28e4e035-b1ab-4665-d45a-70f6fac13a71"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lin_score=  0.0994092270419803\n",
            "r2_score=  0.0994092270419803\n",
            "Acaccury_score=  0.676056338028169\n",
            "Sensitivity= 0.6805555555555556\n",
            "Specificity= 0.6714285714285714\n",
            "MCC: 0.351984126984127\n",
            "Kappa Value: 0.35198412698412695\n",
            "\n",
            "\n",
            "\n",
            "LR_score=  0.6408450704225352\n",
            "r2_score=  -0.4369047619047617\n",
            "Acaccury_score=  0.6408450704225352\n",
            "Sensitivity= 0.6388888888888888\n",
            "Specificity= 0.6428571428571429\n",
            "MCC: 0.28171808490950556\n",
            "Kappa Value: 0.2816901408450704\n",
            "\n",
            "\n",
            "\n",
            "DT_score=  0.647887323943662\n",
            "r2_score=  -0.4087301587301584\n",
            "Acaccury_score=  0.647887323943662\n",
            "Sensitivity= 0.6388888888888888\n",
            "Specificity= 0.6571428571428571\n",
            "MCC: 0.29603174603174603\n",
            "Kappa Value: 0.2959143197143991\n",
            "\n",
            "\n",
            "\n",
            "RF_score=  0.7394366197183099\n",
            "r2_score=  -0.04246031746031731\n",
            "Acaccury_score=  0.7394366197183099\n",
            "Sensitivity= 0.7222222222222222\n",
            "Specificity= 0.7571428571428571\n",
            "MCC: 0.47950781126622216\n",
            "Kappa Value: 0.479079912750347\n",
            "\n",
            "\n",
            "\n",
            "ETC_score=  0.7464788732394366\n",
            "r2_score=  -0.014285714285714013\n",
            "Acaccury_score=  0.7464788732394366\n",
            "Sensitivity= 0.7638888888888888\n",
            "Specificity= 0.7285714285714285\n",
            "MCC: 0.492851624885953\n",
            "Kappa Value: 0.49265581579992057\n",
            "\n",
            "\n",
            "\n",
            "GBC_score=  0.6901408450704225\n",
            "r2_score=  -0.2396825396825395\n",
            "Acaccury_score=  0.6901408450704225\n",
            "Sensitivity= 0.625\n",
            "Specificity= 0.7571428571428571\n",
            "MCC: 0.3852123269916988\n",
            "Kappa Value: 0.3813861386138614\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**PseKRAAC-1**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "m1Q1oQqDu7kU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "df=pd.read_csv('/content/PseKRAAC-1 data.csv')\n",
        "# print(df.head(10))\n",
        "# print (df.isnull().any())\n",
        "x=df.drop('Target', axis=1)\n",
        "y=df['Target']\n",
        "x_train,x_test,y_train,y_test= train_test_split(x,y,test_size=0.30, random_state=8)\n",
        "\n",
        "#Linear Regression\n",
        "clf= LinearRegression()\n",
        "clf.fit(x_train,y_train)\n",
        "LinearRegression()\n",
        "pred=clf.predict(x_test)\n",
        "pred_labels = [round(value) for value in pred]\n",
        "\n",
        "lin_score= clf.score(x_test,y_test)\n",
        "print(\"Lin_score= \",lin_score)\n",
        "from sklearn.metrics import r2_score\n",
        "r2_score=r2_score(y_test,pred)\n",
        "print(\"r2_score= \",r2_score)\n",
        "from sklearn.metrics import accuracy_score #accuracy check\n",
        "acaccury_score= accuracy_score(y_test,pred_labels)\n",
        "print(\"Acaccury_score= \",acaccury_score)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn,fp,fn,tp= confusion_matrix(y_test,pred_labels).ravel()\n",
        "sensitivity= tp/(tp+fn)\n",
        "specificity= tn/(tn+fp)\n",
        "print(f\"Sensitivity= {sensitivity}\")\n",
        "print(f\"Specificity= {specificity}\")\n",
        "from sklearn.metrics import matthews_corrcoef # Calculate Matthews Correlation Coefficient (MCC)\n",
        "mcc = matthews_corrcoef(y_test, pred_labels)\n",
        "print(f\"MCC: {mcc}\")\n",
        "\n",
        "from sklearn.metrics import cohen_kappa_score # Calculate Kappa Value\n",
        "kappa = cohen_kappa_score(y_test, pred_labels)\n",
        "print(f\"Kappa Value: {kappa}\")\n",
        "\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "\n",
        "#Logistic Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "clf=LogisticRegression()\n",
        "clf.fit(x_train,y_train)\n",
        "LogisticRegression()\n",
        "pred=clf.predict(x_test)\n",
        "log_score=clf.score(x_test,y_test)\n",
        "print(\"LR_score= \",log_score)\n",
        "from sklearn.metrics import r2_score\n",
        "r2_score= r2_score(y_test,pred)\n",
        "print(\"r2_score= \",r2_score)\n",
        "from sklearn.metrics import accuracy_score #accuracy check\n",
        "acaccury_score= accuracy_score(y_test,pred)\n",
        "print(\"Acaccury_score= \",acaccury_score)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn,fp,fn,tp= confusion_matrix(y_test,pred).ravel()\n",
        "sensitivity= tp/(tp+fn)\n",
        "specificity= tn/(tn+fp)\n",
        "print(f\"Sensitivity= {sensitivity}\")\n",
        "print(f\"Specificity= {specificity}\")\n",
        "from sklearn.metrics import matthews_corrcoef # Calculate Matthews Correlation Coefficient (MCC)\n",
        "mcc = matthews_corrcoef(y_test, pred)\n",
        "print(f\"MCC: {mcc}\")\n",
        "\n",
        "from sklearn.metrics import cohen_kappa_score # Calculate Kappa Value\n",
        "kappa = cohen_kappa_score(y_test, pred)\n",
        "print(f\"Kappa Value: {kappa}\")\n",
        "\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "\n",
        "#Decision Tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "clf=DecisionTreeClassifier()\n",
        "clf.fit(x_train,y_train)\n",
        "DecisionTreeClassifier()\n",
        "pred=clf.predict(x_test)\n",
        "dt_score=clf.score(x_test,y_test)\n",
        "print(\"DT_score= \",dt_score)\n",
        "from sklearn.metrics import r2_score\n",
        "r2_score= r2_score(y_test,pred)\n",
        "print(\"r2_score= \",r2_score)\n",
        "from sklearn.metrics import accuracy_score #accuracy check\n",
        "acaccury_score= accuracy_score(y_test,pred)\n",
        "print(\"Acaccury_score= \",acaccury_score)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn,fp,fn,tp= confusion_matrix(y_test,pred).ravel()\n",
        "sensitivity= tp/(tp+fn)\n",
        "specificity= tn/(tn+fp)\n",
        "print(f\"Sensitivity= {sensitivity}\")\n",
        "print(f\"Specificity= {specificity}\")\n",
        "from sklearn.metrics import matthews_corrcoef # Calculate Matthews Correlation Coefficient (MCC)\n",
        "mcc = matthews_corrcoef(y_test, pred)\n",
        "print(f\"MCC: {mcc}\")\n",
        "\n",
        "from sklearn.metrics import cohen_kappa_score # Calculate Kappa Value\n",
        "kappa = cohen_kappa_score(y_test, pred)\n",
        "print(f\"Kappa Value: {kappa}\")\n",
        "print(\"\\n\\n\")\n",
        "# from sklearn import tree\n",
        "# tree.plot_tree(clf, filled=True, rounded=True, feature_names=x.columns)\n",
        "# plt.figure(figsize=(10,50))\n",
        "\n",
        "\n",
        "#Random Forest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "clf=RandomForestClassifier()\n",
        "clf.fit(x_train,y_train)\n",
        "RandomForestClassifier()\n",
        "pred=clf.predict(x_test)\n",
        "rf_score=clf.score(x_test,y_test)\n",
        "print(\"RF_score= \",rf_score)\n",
        "from sklearn.metrics import r2_score\n",
        "r2_score= r2_score(y_test,pred)\n",
        "print(\"r2_score= \",r2_score)\n",
        "from sklearn.metrics import accuracy_score #accuracy check\n",
        "acaccury_score= accuracy_score(y_test,pred)\n",
        "print(\"Acaccury_score= \",acaccury_score)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn,fp,fn,tp= confusion_matrix(y_test,pred).ravel()\n",
        "sensitivity= tp/(tp+fn)\n",
        "specificity= tn/(tn+fp)\n",
        "print(f\"Sensitivity= {sensitivity}\")\n",
        "print(f\"Specificity= {specificity}\")\n",
        "from sklearn.metrics import matthews_corrcoef # Calculate Matthews Correlation Coefficient (MCC)\n",
        "mcc = matthews_corrcoef(y_test, pred)\n",
        "print(f\"MCC: {mcc}\")\n",
        "\n",
        "from sklearn.metrics import cohen_kappa_score # Calculate Kappa Value\n",
        "kappa = cohen_kappa_score(y_test, pred)\n",
        "print(f\"Kappa Value: {kappa}\")\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "#Extra Tree Classifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "clf=ExtraTreesClassifier()\n",
        "clf.fit(x_train,y_train)\n",
        "ExtraTreesClassifier()\n",
        "pred=clf.predict(x_test)\n",
        "etc_score=clf.score(x_test,y_test)\n",
        "print(\"ETC_score= \",etc_score)\n",
        "from sklearn.metrics import r2_score\n",
        "r2_score= r2_score(y_test,pred)\n",
        "print(\"r2_score= \",r2_score)\n",
        "from sklearn.metrics import accuracy_score #accuracy check\n",
        "acaccury_score= accuracy_score(y_test,pred)\n",
        "print(\"Acaccury_score= \",acaccury_score)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn,fp,fn,tp= confusion_matrix(y_test,pred).ravel()\n",
        "sensitivity= tp/(tp+fn)\n",
        "specificity= tn/(tn+fp)\n",
        "print(f\"Sensitivity= {sensitivity}\")\n",
        "print(f\"Specificity= {specificity}\")\n",
        "from sklearn.metrics import matthews_corrcoef # Calculate Matthews Correlation Coefficient (MCC)\n",
        "mcc = matthews_corrcoef(y_test, pred)\n",
        "print(f\"MCC: {mcc}\")\n",
        "\n",
        "from sklearn.metrics import cohen_kappa_score # Calculate Kappa Value\n",
        "kappa = cohen_kappa_score(y_test, pred)\n",
        "print(f\"Kappa Value: {kappa}\")\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "#Gradient Boosting Classifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "clf=GradientBoostingClassifier()\n",
        "clf.fit(x_train,y_train)\n",
        "GradientBoostingClassifier()\n",
        "pred=clf.predict(x_test)\n",
        "gbc_score=clf.score(x_test,y_test)\n",
        "print(\"GBC_score= \",gbc_score)\n",
        "from sklearn.metrics import r2_score\n",
        "r2_score= r2_score(y_test,pred)\n",
        "print(\"r2_score= \",r2_score)\n",
        "from sklearn.metrics import accuracy_score #accuracy check\n",
        "acaccury_score= accuracy_score(y_test,pred)\n",
        "print(\"Acaccury_score= \",acaccury_score)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn,fp,fn,tp= confusion_matrix(y_test,pred).ravel()\n",
        "sensitivity= tp/(tp+fn)\n",
        "specificity= tn/(tn+fp)\n",
        "print(f\"Sensitivity= {sensitivity}\")\n",
        "print(f\"Specificity= {specificity}\")\n",
        "from sklearn.metrics import matthews_corrcoef # Calculate Matthews Correlation Coefficient (MCC)\n",
        "mcc = matthews_corrcoef(y_test, pred)\n",
        "print(f\"MCC: {mcc}\")\n",
        "\n",
        "from sklearn.metrics import cohen_kappa_score # Calculate Kappa Value\n",
        "kappa = cohen_kappa_score(y_test, pred)\n",
        "print(f\"Kappa Value: {kappa}\")\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5GQ899Pu7t4",
        "outputId": "e9ffb73b-6a8e-43c7-c2e9-e62b971f5a81"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lin_score=  0.020613518552326737\n",
            "r2_score=  0.020613518552326737\n",
            "Acaccury_score=  0.5422535211267606\n",
            "Sensitivity= 0.5\n",
            "Specificity= 0.5857142857142857\n",
            "MCC: 0.08601346388644363\n",
            "Kappa Value: 0.08559540320982761\n",
            "\n",
            "\n",
            "\n",
            "LR_score=  0.5422535211267606\n",
            "r2_score=  -0.8313492063492061\n",
            "Acaccury_score=  0.5422535211267606\n",
            "Sensitivity= 0.5\n",
            "Specificity= 0.5857142857142857\n",
            "MCC: 0.08601346388644363\n",
            "Kappa Value: 0.08559540320982761\n",
            "\n",
            "\n",
            "\n",
            "DT_score=  0.4647887323943662\n",
            "r2_score=  -1.1412698412698408\n",
            "Acaccury_score=  0.4647887323943662\n",
            "Sensitivity= 0.3888888888888889\n",
            "Specificity= 0.5428571428571428\n",
            "MCC: -0.06908131928870279\n",
            "Kappa Value: -0.06809184481393515\n",
            "\n",
            "\n",
            "\n",
            "RF_score=  0.49295774647887325\n",
            "r2_score=  -1.028571428571428\n",
            "Acaccury_score=  0.49295774647887325\n",
            "Sensitivity= 0.5\n",
            "Specificity= 0.4857142857142857\n",
            "MCC: -0.014285714285714285\n",
            "Kappa Value: -0.014285714285714235\n",
            "\n",
            "\n",
            "\n",
            "ETC_score=  0.47183098591549294\n",
            "r2_score=  -1.1130952380952377\n",
            "Acaccury_score=  0.47183098591549294\n",
            "Sensitivity= 0.4305555555555556\n",
            "Specificity= 0.5142857142857142\n",
            "MCC: -0.0553512568528503\n",
            "Kappa Value: -0.05508222706558352\n",
            "\n",
            "\n",
            "\n",
            "GBC_score=  0.5352112676056338\n",
            "r2_score=  -0.8595238095238091\n",
            "Acaccury_score=  0.5352112676056338\n",
            "Sensitivity= 0.5416666666666666\n",
            "Specificity= 0.5285714285714286\n",
            "MCC: 0.07023809523809524\n",
            "Kappa Value: 0.07023809523809521\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**PseKAAC-7**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "VVfwzp6Eu72u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "df=pd.read_csv('/content/PseKRAAC-7   data.csv')\n",
        "# print(df.head(10))\n",
        "# print (df.isnull().any())\n",
        "x=df.drop('Target', axis=1)\n",
        "y=df['Target']\n",
        "x_train,x_test,y_train,y_test= train_test_split(x,y,test_size=0.30, random_state=8)\n",
        "\n",
        "#Linear Regression\n",
        "clf= LinearRegression()\n",
        "clf.fit(x_train,y_train)\n",
        "LinearRegression()\n",
        "pred=clf.predict(x_test)\n",
        "pred_labels = [round(value) for value in pred]\n",
        "\n",
        "lin_score= clf.score(x_test,y_test)\n",
        "print(\"Lin_score= \",lin_score)\n",
        "from sklearn.metrics import r2_score\n",
        "r2_score=r2_score(y_test,pred)\n",
        "print(\"r2_score= \",r2_score)\n",
        "from sklearn.metrics import accuracy_score #accuracy check\n",
        "acaccury_score= accuracy_score(y_test,pred_labels)\n",
        "print(\"Acaccury_score= \",acaccury_score)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn,fp,fn,tp= confusion_matrix(y_test,pred_labels).ravel()\n",
        "sensitivity= tp/(tp+fn)\n",
        "specificity= tn/(tn+fp)\n",
        "print(f\"Sensitivity= {sensitivity}\")\n",
        "print(f\"Specificity= {specificity}\")\n",
        "from sklearn.metrics import matthews_corrcoef # Calculate Matthews Correlation Coefficient (MCC)\n",
        "mcc = matthews_corrcoef(y_test, pred_labels)\n",
        "print(f\"MCC: {mcc}\")\n",
        "\n",
        "from sklearn.metrics import cohen_kappa_score # Calculate Kappa Value\n",
        "kappa = cohen_kappa_score(y_test, pred_labels)\n",
        "print(f\"Kappa Value: {kappa}\")\n",
        "\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "\n",
        "#Logistic Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "clf=LogisticRegression()\n",
        "clf.fit(x_train,y_train)\n",
        "LogisticRegression()\n",
        "pred=clf.predict(x_test)\n",
        "log_score=clf.score(x_test,y_test)\n",
        "print(\"LR_score= \",log_score)\n",
        "from sklearn.metrics import r2_score\n",
        "r2_score= r2_score(y_test,pred)\n",
        "print(\"r2_score= \",r2_score)\n",
        "from sklearn.metrics import accuracy_score #accuracy check\n",
        "acaccury_score= accuracy_score(y_test,pred)\n",
        "print(\"Acaccury_score= \",acaccury_score)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn,fp,fn,tp= confusion_matrix(y_test,pred).ravel()\n",
        "sensitivity= tp/(tp+fn)\n",
        "specificity= tn/(tn+fp)\n",
        "print(f\"Sensitivity= {sensitivity}\")\n",
        "print(f\"Specificity= {specificity}\")\n",
        "from sklearn.metrics import matthews_corrcoef # Calculate Matthews Correlation Coefficient (MCC)\n",
        "mcc = matthews_corrcoef(y_test, pred)\n",
        "print(f\"MCC: {mcc}\")\n",
        "\n",
        "from sklearn.metrics import cohen_kappa_score # Calculate Kappa Value\n",
        "kappa = cohen_kappa_score(y_test, pred)\n",
        "print(f\"Kappa Value: {kappa}\")\n",
        "\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "\n",
        "#Decision Tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "clf=DecisionTreeClassifier()\n",
        "clf.fit(x_train,y_train)\n",
        "DecisionTreeClassifier()\n",
        "pred=clf.predict(x_test)\n",
        "dt_score=clf.score(x_test,y_test)\n",
        "print(\"DT_score= \",dt_score)\n",
        "from sklearn.metrics import r2_score\n",
        "r2_score= r2_score(y_test,pred)\n",
        "print(\"r2_score= \",r2_score)\n",
        "from sklearn.metrics import accuracy_score #accuracy check\n",
        "acaccury_score= accuracy_score(y_test,pred)\n",
        "print(\"Acaccury_score= \",acaccury_score)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn,fp,fn,tp= confusion_matrix(y_test,pred).ravel()\n",
        "sensitivity= tp/(tp+fn)\n",
        "specificity= tn/(tn+fp)\n",
        "print(f\"Sensitivity= {sensitivity}\")\n",
        "print(f\"Specificity= {specificity}\")\n",
        "from sklearn.metrics import matthews_corrcoef # Calculate Matthews Correlation Coefficient (MCC)\n",
        "mcc = matthews_corrcoef(y_test, pred)\n",
        "print(f\"MCC: {mcc}\")\n",
        "\n",
        "from sklearn.metrics import cohen_kappa_score # Calculate Kappa Value\n",
        "kappa = cohen_kappa_score(y_test, pred)\n",
        "print(f\"Kappa Value: {kappa}\")\n",
        "print(\"\\n\\n\")\n",
        "# from sklearn import tree\n",
        "# tree.plot_tree(clf, filled=True, rounded=True, feature_names=x.columns)\n",
        "# plt.figure(figsize=(10,50))\n",
        "\n",
        "\n",
        "#Random Forest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "clf=RandomForestClassifier()\n",
        "clf.fit(x_train,y_train)\n",
        "RandomForestClassifier()\n",
        "pred=clf.predict(x_test)\n",
        "rf_score=clf.score(x_test,y_test)\n",
        "print(\"RF_score= \",rf_score)\n",
        "from sklearn.metrics import r2_score\n",
        "r2_score= r2_score(y_test,pred)\n",
        "print(\"r2_score= \",r2_score)\n",
        "from sklearn.metrics import accuracy_score #accuracy check\n",
        "acaccury_score= accuracy_score(y_test,pred)\n",
        "print(\"Acaccury_score= \",acaccury_score)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn,fp,fn,tp= confusion_matrix(y_test,pred).ravel()\n",
        "sensitivity= tp/(tp+fn)\n",
        "specificity= tn/(tn+fp)\n",
        "print(f\"Sensitivity= {sensitivity}\")\n",
        "print(f\"Specificity= {specificity}\")\n",
        "from sklearn.metrics import matthews_corrcoef # Calculate Matthews Correlation Coefficient (MCC)\n",
        "mcc = matthews_corrcoef(y_test, pred)\n",
        "print(f\"MCC: {mcc}\")\n",
        "\n",
        "from sklearn.metrics import cohen_kappa_score # Calculate Kappa Value\n",
        "kappa = cohen_kappa_score(y_test, pred)\n",
        "print(f\"Kappa Value: {kappa}\")\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "#Extra Tree Classifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "clf=ExtraTreesClassifier()\n",
        "clf.fit(x_train,y_train)\n",
        "ExtraTreesClassifier()\n",
        "pred=clf.predict(x_test)\n",
        "etc_score=clf.score(x_test,y_test)\n",
        "print(\"ETC_score= \",etc_score)\n",
        "from sklearn.metrics import r2_score\n",
        "r2_score= r2_score(y_test,pred)\n",
        "print(\"r2_score= \",r2_score)\n",
        "from sklearn.metrics import accuracy_score #accuracy check\n",
        "acaccury_score= accuracy_score(y_test,pred)\n",
        "print(\"Acaccury_score= \",acaccury_score)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn,fp,fn,tp= confusion_matrix(y_test,pred).ravel()\n",
        "sensitivity= tp/(tp+fn)\n",
        "specificity= tn/(tn+fp)\n",
        "print(f\"Sensitivity= {sensitivity}\")\n",
        "print(f\"Specificity= {specificity}\")\n",
        "from sklearn.metrics import matthews_corrcoef # Calculate Matthews Correlation Coefficient (MCC)\n",
        "mcc = matthews_corrcoef(y_test, pred)\n",
        "print(f\"MCC: {mcc}\")\n",
        "\n",
        "from sklearn.metrics import cohen_kappa_score # Calculate Kappa Value\n",
        "kappa = cohen_kappa_score(y_test, pred)\n",
        "print(f\"Kappa Value: {kappa}\")\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "#Gradient Boosting Classifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "clf=GradientBoostingClassifier()\n",
        "clf.fit(x_train,y_train)\n",
        "GradientBoostingClassifier()\n",
        "pred=clf.predict(x_test)\n",
        "gbc_score=clf.score(x_test,y_test)\n",
        "print(\"GBC_score= \",gbc_score)\n",
        "from sklearn.metrics import r2_score\n",
        "r2_score= r2_score(y_test,pred)\n",
        "print(\"r2_score= \",r2_score)\n",
        "from sklearn.metrics import accuracy_score #accuracy check\n",
        "acaccury_score= accuracy_score(y_test,pred)\n",
        "print(\"Acaccury_score= \",acaccury_score)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "tn,fp,fn,tp= confusion_matrix(y_test,pred).ravel()\n",
        "sensitivity= tp/(tp+fn)\n",
        "specificity= tn/(tn+fp)\n",
        "print(f\"Sensitivity= {sensitivity}\")\n",
        "print(f\"Specificity= {specificity}\")\n",
        "from sklearn.metrics import matthews_corrcoef # Calculate Matthews Correlation Coefficient (MCC)\n",
        "mcc = matthews_corrcoef(y_test, pred)\n",
        "print(f\"MCC: {mcc}\")\n",
        "\n",
        "from sklearn.metrics import cohen_kappa_score # Calculate Kappa Value\n",
        "kappa = cohen_kappa_score(y_test, pred)\n",
        "print(f\"Kappa Value: {kappa}\")\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qlQDCxs2vsA4",
        "outputId": "41cce235-3f8a-40ee-c3cc-793c73813131"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lin_score=  0.00759576599329137\n",
            "r2_score=  0.00759576599329137\n",
            "Acaccury_score=  0.5422535211267606\n",
            "Sensitivity= 0.7916666666666666\n",
            "Specificity= 0.2857142857142857\n",
            "MCC: 0.08976838826852591\n",
            "Kappa Value: 0.07792207792207795\n",
            "\n",
            "\n",
            "\n",
            "LR_score=  0.5422535211267606\n",
            "r2_score=  -0.8313492063492061\n",
            "Acaccury_score=  0.5422535211267606\n",
            "Sensitivity= 0.7916666666666666\n",
            "Specificity= 0.2857142857142857\n",
            "MCC: 0.08976838826852591\n",
            "Kappa Value: 0.07792207792207795\n",
            "\n",
            "\n",
            "\n",
            "DT_score=  0.5140845070422535\n",
            "r2_score=  -0.9440476190476188\n",
            "Acaccury_score=  0.5140845070422535\n",
            "Sensitivity= 0.5416666666666666\n",
            "Specificity= 0.4857142857142857\n",
            "MCC: 0.02742178902166201\n",
            "Kappa Value: 0.027397260273972712\n",
            "\n",
            "\n",
            "\n",
            "RF_score=  0.5352112676056338\n",
            "r2_score=  -0.8595238095238091\n",
            "Acaccury_score=  0.5352112676056338\n",
            "Sensitivity= 0.5972222222222222\n",
            "Specificity= 0.4714285714285714\n",
            "MCC: 0.06920221450629686\n",
            "Kappa Value: 0.06875993640699518\n",
            "\n",
            "\n",
            "\n",
            "ETC_score=  0.5140845070422535\n",
            "r2_score=  -0.9440476190476188\n",
            "Acaccury_score=  0.5140845070422535\n",
            "Sensitivity= 0.5277777777777778\n",
            "Specificity= 0.5\n",
            "MCC: 0.027786048666089032\n",
            "Kappa Value: 0.02778329033538396\n",
            "\n",
            "\n",
            "\n",
            "GBC_score=  0.5140845070422535\n",
            "r2_score=  -0.9440476190476188\n",
            "Acaccury_score=  0.5140845070422535\n",
            "Sensitivity= 0.5555555555555556\n",
            "Specificity= 0.4714285714285714\n",
            "MCC: 0.02707831270499151\n",
            "Kappa Value: 0.02701092353525325\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMQxuSpJ9c3C+P8MR8xnSP8",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}